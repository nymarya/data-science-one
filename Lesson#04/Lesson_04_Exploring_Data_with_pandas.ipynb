{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson_04_Exploring_Data_with_pandas.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "WAcXh6j8sySe",
        "toc-hr-collapsed": true
      },
      "cell_type": "markdown",
      "source": [
        "## 1 Exploring Data with pandas\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TvYRdrKt_M8Y"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 Introduction\n"
      ]
    },
    {
      "metadata": {
        "id": "3Niv9xgJzqeB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "In pandas, each axis has labels, and we've learned to use loc[] to specify labels to create our selection:\n",
        "\n",
        "<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=19qbWRXXH0SrBu2FnMREay_KyvifucKNd\">\n",
        "\n",
        "\n",
        "In some scenarios, like specifying specific columns, using labels to make selections makes things easier - in others though, it makes things harder. If you wanted to select the tenth to twentieth rows in a dataframe, you'd need to know their labels first.\n",
        "\n",
        "In this lesson, we'll learn how to index by integer position with pandas. We'll also learn more advanced selection techniques which will help us perform more complex data analysis.\n",
        "\n",
        "We'll continue to use the Fortune Global 500 (2017) dataset from the previous lesson."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-1zPyxT4BlDt"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 Using iloc to select by integer position\n"
      ]
    },
    {
      "metadata": {
        "id": "awaWEXwa0B4f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To select data by integer position using pandas we use the [Dataframe.iloc[]](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iloc.html) method and the [Series.iloc[]](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.iloc.html) method. It's easy to get loc[] and iloc[] confused at first, but the easiest way is to remember the first letter of each method:\n",
        "\n",
        "- **loc**: **l**able based selection\n",
        "- **iloc**: **integer** position based selection\n",
        "\n",
        "Using the **iloc[]** methods is almost identical to indexing with NumPy, with integer positions starting at **0** like ndarrays and Python lists. Let's take a look at how we would perform our selection from the previous screen using **iloc[]:**\n",
        "\n",
        "<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1dQa9Y1ZVbYHCA0BhQxWL5FPgJVPAyU1P\">\n",
        "\n",
        "\n",
        "As you can see, **DataFrame.iloc[]** behaves similarly to **DataFrame.loc[]**. The full syntax for **DataFrame.iloc[]**, in psuedocode, is:\n",
        "\n",
        "```python\n",
        "df.iloc[row,column]\n",
        "```\n",
        "\n",
        "The valid inputs for row and column are almost identical to when you use **DataFrame.loc[]**, with the distinction being that you are using integers rather than labels:\n",
        "\n",
        "- A single integer position.\n",
        "- A list or array of integer positions.\n",
        "- A slice object with integer positions.\n",
        "- A boolean array.\n",
        "\n",
        "Let's say we wanted to select just the first column from our **f500** dataframe. To do this, we use the : wildcards to specify all rows, and then use the integer 0 to specify the first column:\n",
        "\n",
        "```python\n",
        "first_column = f500.iloc[:,0]\n",
        "print(first_column)\n",
        "```\n",
        "```python\n",
        "0                        Walmart\n",
        "1                     State Grid\n",
        "2                  Sinopec Group\n",
        "...\n",
        "497    Wm. Morrison Supermarkets\n",
        "498                          TUI\n",
        "499                   AutoNation\n",
        "Name: company, dtype: object\n",
        "```\n",
        "\n",
        "If we wanted to select a single row, we don't need to specify a column wildcard. Let's see how we'd select just the fourth row:\n",
        "\n",
        "```python\n",
        "fourth_row = f500.iloc[3]\n",
        "print(fourth_row)\n",
        "```\n",
        "```python\n",
        "company                 China National Petroleum\n",
        "rank                                           4\n",
        "revenues                                  262573\n",
        "revenue_change                             -12.3\n",
        "profits                                   1867.5\n",
        "assets                                    585619\n",
        "profit_change                              -73.7\n",
        "ceo                                Zhang Jianhua\n",
        "industry                      Petroleum Refining\n",
        "sector                                    Energy\n",
        "previous_rank                                  3\n",
        "country                                    China\n",
        "hq_location                       Beijing, China\n",
        "website                   http://www.cnpc.com.cn\n",
        "years_on_global_500_list                      17\n",
        "employees                                1512048\n",
        "total_stockholder_equity                  301893\n",
        "Name: 3, dtype: object\n",
        "```\n",
        "\n",
        "If we are specifying a positional slice, we can take advantage of the same shortcut that we use with labels, using brackets without **loc**. Here's how we would select the rows between index positions one up to and including four:\n",
        "\n",
        "```python\n",
        "second_to_fifth_rows = f500[1:5]\n",
        "```\n",
        "\n",
        "```python\n",
        "company  rank  revenues ... employees  total_stockholder_equity\n",
        "1         State Grid     2    315199 ...    926067                    209456\n",
        "2      Sinopec Group     3    267518 ...    713288                    106523\n",
        "3  China National...     4    262573 ...   1512048                    301893\n",
        "4       Toyota Motor     5    254694 ...    364445                    157210\n",
        "```\n",
        "\n",
        "In the example above, the row at index position 5 is not included, just like if we were slicing with a Python list. It's worth reiterating again that **iloc[]** handles slicing differently, as we learned in the previous mission:\n",
        "\n",
        "- With **loc[]**, the **ending slice is included.**\n",
        "- With **iloc[]**, the **ending slice is not included.**\n",
        "\n",
        "The table below summarizes how we can use **DataFrame.iloc[]** and **Series.iloc[]** to select by integer position:\n",
        "\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=18jhblUrPsASHHdT5Lgpr6mmPmaIYo6og\">\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "We have provided code to read the **f500.csv** file into a dataframe and assigned it to **f500**, and inserted **NaN** values into the **previous_rank** column as we did in the previous section.\n",
        "\n",
        "- Select just the fifth row of the **f500** dataframe, assigning the result to **fifth_row.**\n",
        "- Select the first three rows of the **f500** dataframe, assigning the result to **first_three_rows.**\n",
        "- Select the first and seventh rows and the first 5 columns of the **f500** dataframe, assigning the result to **first_seventh_row_slice**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1MTPfNm7AD3J",
        "outputId": "aab20916-d931-4187-d419-1ba73c6b883c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/nymarya/data-science-one/master/Lesson%2304/f500.csv'\n",
        "f500 = pd.read_csv(url, index_col=0)\n",
        "f500.index.name = None\n",
        "f500.loc[f500[\"previous_rank\"] == 0, \"previous_rank\"] = np.nan\n",
        "\n",
        "\n",
        "fifth_row = f500.iloc[5]\n",
        "first_three_rows = f500.iloc[:3]\n",
        "first_seventh_row_slice = f500.iloc[[0,6],:5]\n",
        "\n",
        "print(\"FIFTH ROW\\n\")\n",
        "print(fifth_row)\n",
        "print(\"\\nFIRST THREE ROWS\\n\")\n",
        "print(first_three_rows)\n",
        "print(\"\\nFIRST SEVENTH ROW\\n\")\n",
        "print(first_seventh_row_slice)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FIFTH ROW\n",
            "\n",
            "rank                                                6\n",
            "revenues                                       240264\n",
            "revenue_change                                    1.5\n",
            "profits                                        5937.3\n",
            "assets                                         432116\n",
            "profit_change                                     NaN\n",
            "ceo                                   Matthias Muller\n",
            "industry                     Motor Vehicles and Parts\n",
            "sector                         Motor Vehicles & Parts\n",
            "previous_rank                                       7\n",
            "country                                       Germany\n",
            "hq_location                        Wolfsburg, Germany\n",
            "website                     http://www.volkswagen.com\n",
            "years_on_global_500_list                           23\n",
            "employees                                      626715\n",
            "total_stockholder_equity                        97753\n",
            "Name: Volkswagen, dtype: object\n",
            "\n",
            "FIRST THREE ROWS\n",
            "\n",
            "               rank  revenues  revenue_change  profits  assets  profit_change  \\\n",
            "Walmart           1    485873             0.8  13643.0  198825           -7.2   \n",
            "State Grid        2    315199            -4.4   9571.3  489838           -6.2   \n",
            "Sinopec Group     3    267518            -9.1   1257.9  310726          -65.0   \n",
            "\n",
            "                               ceo               industry     sector  \\\n",
            "Walmart        C. Douglas McMillon  General Merchandisers  Retailing   \n",
            "State Grid                 Kou Wei              Utilities     Energy   \n",
            "Sinopec Group            Wang Yupu     Petroleum Refining     Energy   \n",
            "\n",
            "               previous_rank country      hq_location                 website  \\\n",
            "Walmart                  1.0     USA  Bentonville, AR  http://www.walmart.com   \n",
            "State Grid               2.0   China   Beijing, China  http://www.sgcc.com.cn   \n",
            "Sinopec Group            4.0   China   Beijing, China  http://www.sinopec.com   \n",
            "\n",
            "               years_on_global_500_list  employees  total_stockholder_equity  \n",
            "Walmart                              23    2300000                     77798  \n",
            "State Grid                           17     926067                    209456  \n",
            "Sinopec Group                        19     713288                    106523  \n",
            "\n",
            "FIRST SEVENTH ROW\n",
            "\n",
            "                   rank  revenues  revenue_change  profits  assets\n",
            "Walmart               1    485873             0.8  13643.0  198825\n",
            "Royal Dutch Shell     7    240033           -11.8   4575.0  411275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gGUK5R5HFOmV"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.3 Reading CSV files with pandas\n"
      ]
    },
    {
      "metadata": {
        "id": "m1Xb7brp0-VW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "So far, we've provided the code to read the CSV file into pandas for you. In this mission, we're going to teach you how to use the [pandas.read_csv()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function to read in CSV files. Before we start, let's take a look at the first few lines of our CSV file in its raw form. To make it easier to read, we're only showing the first four columns from each line:\n",
        "\n",
        "```python\n",
        "company,rank,revenues,revenue_change\n",
        "Walmart,1,485873,0.8\n",
        "State Grid,2,315199,-4.4\n",
        "Sinopec Group,3,267518,-9.1\n",
        "China National Petroleum,4,262573,-12.3\n",
        "Toyota Motor,5,254694,7.7\n",
        "```\n",
        "\n",
        "Now let's take a moment to look at the code segment we've been using to read in the files.\n",
        "\n",
        "```python\n",
        "f500 = pd.read_csv(\"f500.csv\", index_col=0)\n",
        "f500.index.name = None\n",
        "```\n",
        "\n",
        "\n",
        "Looking at the first line only, we use the **pandas.read_csv()** function with an unnamed argument, the name of the CSV file, and a named argument for the **index_col** parameter. The **index_col** parameter specifies which column to use as the row labels. We use a value of **0** to specify that we want to use the first column.\n",
        "\n",
        "Let's look at what the **f500** dataframe looks like after that first line. We'll use **DataFrame.iloc[]** to show the first 5 rows and the first 3 columns:\n",
        "\n",
        "```python\n",
        ">>> f500 = pd.read_csv(\"f500.csv\", index_col=0)\n",
        "\n",
        ">>> print(f500.iloc[:5, :3])\n",
        "\n",
        "                              rank  revenues  revenue_change\n",
        "    company                                                    \n",
        "    Walmart                      1    485873             0.8\n",
        "    State Grid                   2    315199            -4.4\n",
        "    Sinopec Group                3    267518            -9.1\n",
        "    China National Petroleum     4    262573           -12.3\n",
        "    Toyota Motor                 5    254694             7.7\n",
        "```\n",
        "\n",
        "Notice that above the index labels is the text **company**. This is the value from the start of the first row of the CSV, effectively the name of the first column. Pandas has used this value as the **axis name** for the index axis. Both the column and index axes can have names assigned to them. The next line of code removes that name:\n",
        "\n",
        "```python\n",
        "f500.index.name = None\n",
        "```\n",
        "\n",
        "First, we use **DataFrame.index** to access the index axes attribute, and then we use **index.name** to access the name of the index axes. By setting this to **None** we remove the name. Let's look at what it looks like after this action\n",
        "\n",
        "```python\n",
        ">>> f500.index.name = None\n",
        "\n",
        ">>> print(f500.iloc[:5, :3])\n",
        "\n",
        "                              rank  revenues  revenue_change\n",
        "    Walmart                      1    485873             0.8\n",
        "    State Grid                   2    315199            -4.4\n",
        "    Sinopec Group                3    267518            -9.1\n",
        "    China National Petroleum     4    262573           -12.3\n",
        "    Toyota Motor                 5    254694             7.7\n",
        "```\n",
        "\n",
        "The index name has been removed.\n",
        "\n",
        "The **index_col** parameter we used is an optional argument. Let's look at what it looks like if we use **pandas.read_csv()** without it:\n",
        "\n",
        "```python\n",
        ">>> f500 = pd.read_csv(\"f500.csv\")\n",
        "\n",
        ">>> print(f500.iloc[:5,:3])\n",
        "\n",
        "                        company  rank  revenues\n",
        "    0                   Walmart     1    485873\n",
        "    1                State Grid     2    315199\n",
        "    2             Sinopec Group     3    267518\n",
        "    3  China National Petroleum     4    262573\n",
        "    4              Toyota Motor     5    254694\n",
        "```\n",
        "\n",
        "There two differences with this approach:\n",
        "\n",
        "- The **company** column is now included as a regular column, instead of being used for the index.\n",
        "- The index labels are now integers starting from **0**.\n",
        "- This is the more conventional way to read in a dataframe, and it's the method we'll use from here on in. There are a few things to be aware of when you have an integer index labels, and we'll talk about them in the next screen.\n",
        "\n",
        "\n",
        "For now, let's re-read in the CSV file using the conventional method:\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "The pandas library is already imported from the previous screen.\n",
        "\n",
        "- Use the **pandas.read_csv()** function to read the **f500.csv** CSV file as a pandas dataframe, and assign it to the variable name **f500**.\n",
        "  - Do not use the **index_col** parameter, so that the dataframe has integer index labels.\n",
        "- Use the code below to insert the **NaN** values into the **previous_rank** column: \n",
        "```python\n",
        "f500.loc[f500[\"previous_rank\"] == 0, \"previous_rank\"] = np.nan\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7YDIZ_uOG5S5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "f500 = pd.read_csv(url, index_col=0)\n",
        "f500.index.name = None\n",
        "f500.loc[f500[\"previous_rank\"] == 0, \"previous_rank\"] = np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zxq9CFkx6-lZ"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.4 Working with Integer Labels\n"
      ]
    },
    {
      "metadata": {
        "id": "gRZ6gjFR1pIN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "As we observed in the previous subsection, our index labels are now integers compared with previously where all our index labels were strings. As a result, this means, that while our dataframe has all of the rows, in the same order, as when we read it in, that the integer position and the label for the index axis is the same. Let's look at an example:\n",
        "\n",
        "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1VeQE7W6ylvfg524QrO2tJ_-iFRud_04F\">\n",
        "\n",
        "\n",
        "Because the index axis of our dataframe has labels that are identical to the integer positions, both **loc[]** and **iloc[]** give the same result. But what if we have modified our dataframe in some way. Let's reorder the rows of our dataframe, and then see what happens:\n",
        "\n",
        "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1KT2Dus_gxSDfPeBSSxqNkoU8NWXJFlVk\">\n",
        "\n",
        "Now we get different results. When we use **df.iloc[1]** it still selects the second row, since **DataFrame.iloc[]** uses integer position. However, **df.loc[1]** selects the **third rowâ€“ DataFrame.loc[]** itself doesn't mind that the rows are out of order, it just looks at the axis labels and selects the row with the matching label.\n",
        "\n",
        "This is one of the most confusing parts of selecting data with pandas. You might not come across it often, because a lot of the time you'll work with a dataframe where the index labels are integers, and the dataframe contains all of its original rows, in order. You can use **DataFrame.iloc[]** and **DataFrame.loc[]** interchangeably and it doesn't matter which you chose.\n",
        "\n",
        "Then, you remove some rows or change the order, and suddenly you're getting errors or unexpected behavior. For this reason, it's important to make sure that when you're selecting data you're always asking yourself, \"Do I want to select based on position or label?\" and choosing **DataFrame.iloc** or **DataFrame.loc[]** accordingly. Let's look at some examples with our **f500** dataframe where we come across this 'gotcha' to do with integer labels.\n",
        "\n",
        "Let's say that we wanted to select just the Swedish companies from the Fortune 500:\n",
        "\n",
        "```python\n",
        ">>> swedish = f500.loc[f500[\"country\"] == \"Sweden\",\"company\":\"revenues\"]\n",
        "\n",
        ">>> print(swedish)\n",
        "\n",
        "                        company  rank  revenues\n",
        "    300                   Volvo   301     35269\n",
        "    418             LM Ericsson   419     26004\n",
        "    481  H & M Hennes & Mauritz   482     22618\n",
        "```\n",
        "\n",
        "If we wanted to select the first company from our new swedish dataframe, we can use **DataFrame.iloc[]**:\n",
        "\n",
        "```python\n",
        ">>> first_swedish = swedish.iloc[0]\n",
        "\n",
        ">>> print(first_swedish)\n",
        "\n",
        "    company     Volvo\n",
        "    rank          301\n",
        "    revenues    35269\n",
        "    Name: 300, dtype: object\n",
        "```\n",
        "\n",
        "Let's see what happens when we use **DataFrame.loc[]** instead of **DataFrame.iloc[]**:\n",
        "\n",
        "```python\n",
        ">>> first_swedish = swedish.loc[0]\n",
        "\n",
        "    ---------------------------------------------------------------------------\n",
        "    KeyError                                  Traceback (most recent call last)\n",
        "    /python3.4/site-packages/pandas/core/indexing.py in _has_valid_type(self, key, axis)\n",
        "       1410                 if key not in ax:\n",
        "    -> 1411                     error()\n",
        "       1412             except TypeError as e:\n",
        "\n",
        "    /python3.4/site-packages/pandas/core/indexing.py in error()\n",
        "       1405                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n",
        "    -> 1406                                (key, self.obj._get_axis_name(axis)))\n",
        "       1407 \n",
        "\n",
        "    KeyError: 'the label [0] is not in the [index]'\n",
        "```\n",
        "\n",
        "We get an error, telling us that **the label [0] is not in the [index]** (the actual traceback for this error is much longer than this, we have truncated it for brevity). And indeed, there is no row that has a label **0** in the index of our **swedish** dataframe.\n",
        "\n",
        "The four most common times we will see this is when we alter the rows in our dataframe by:\n",
        "\n",
        "1. Selecting a subset of the data (like in the example above).\n",
        "2. Removing certain rows, for example if they have null values (which we'll explore in the next mission).\n",
        "3. Randomizing the order of the rows in our dataframe (which is commonly done to perform machine learning).\n",
        "4. Sorting the rows.\n",
        "\n",
        "Regardless of how we altered the dataframe, the way to avoid this is the same: Always think carefully and deliberately about whether you want to select by label or integer position, and use **DataFrame.loc[]** or **DataFrame.iloc[]** accordingly.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "In the code below, we have used the [DataFrame.sort_values()](https://www.dataquest.io/m/292/exploring-data-with-pandas/4/working-with-integer-labels) method to sort the rows in the **f500** dataframe by the employees column from most to least employees, and have assigned the resulting dataframe to **sorted_emp**.\n",
        "\n",
        "  - Assign the first five rows of the **sorted_emp** dataframe to the variable **top5_emp**, by choosing the correct method out of either **loc[]** or **iloc[].**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9cR5waV97v9s",
        "outputId": "8da510ca-47aa-4d7f-d359-ddb5ede8532c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "cell_type": "code",
      "source": [
        "sorted_emp = f500.sort_values(\"employees\", ascending=False)\n",
        "\n",
        "# put your code here\n",
        "top5_emp = sorted_emp.iloc[:5]\n",
        "print(top5_emp)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            rank  revenues  revenue_change  profits   assets  \\\n",
            "Walmart                        1    485873             0.8  13643.0   198825   \n",
            "China National Petroleum       4    262573           -12.3   1867.5   585619   \n",
            "China Post Group             119     65605            -5.8   4980.3  1221649   \n",
            "State Grid                     2    315199            -4.4   9571.3   489838   \n",
            "Hon Hai Precision Industry    27    135129            -4.3   4608.8    80436   \n",
            "\n",
            "                            profit_change                  ceo  \\\n",
            "Walmart                              -7.2  C. Douglas McMillon   \n",
            "China National Petroleum            -73.7        Zhang Jianhua   \n",
            "China Post Group                     18.7            Li Guohua   \n",
            "State Grid                           -6.2              Kou Wei   \n",
            "Hon Hai Precision Industry           -0.4            Terry Gou   \n",
            "\n",
            "                                                       industry  \\\n",
            "Walmart                                   General Merchandisers   \n",
            "China National Petroleum                     Petroleum Refining   \n",
            "China Post Group            Mail, Package, and Freight Delivery   \n",
            "State Grid                                            Utilities   \n",
            "Hon Hai Precision Industry       Electronics, Electrical Equip.   \n",
            "\n",
            "                                    sector  previous_rank country  \\\n",
            "Walmart                          Retailing            1.0     USA   \n",
            "China National Petroleum            Energy            3.0   China   \n",
            "China Post Group            Transportation          105.0   China   \n",
            "State Grid                          Energy            2.0   China   \n",
            "Hon Hai Precision Industry      Technology           25.0  Taiwan   \n",
            "\n",
            "                                        hq_location  \\\n",
            "Walmart                             Bentonville, AR   \n",
            "China National Petroleum             Beijing, China   \n",
            "China Post Group                     Beijing, China   \n",
            "State Grid                           Beijing, China   \n",
            "Hon Hai Precision Industry  New Taipei City, Taiwan   \n",
            "\n",
            "                                                website  \\\n",
            "Walmart                          http://www.walmart.com   \n",
            "China National Petroleum         http://www.cnpc.com.cn   \n",
            "China Post Group            http://www.chinapost.com.cn   \n",
            "State Grid                       http://www.sgcc.com.cn   \n",
            "Hon Hai Precision Industry       http://www.foxconn.com   \n",
            "\n",
            "                            years_on_global_500_list  employees  \\\n",
            "Walmart                                           23    2300000   \n",
            "China National Petroleum                          17    1512048   \n",
            "China Post Group                                   7     941211   \n",
            "State Grid                                        17     926067   \n",
            "Hon Hai Precision Industry                        13     726772   \n",
            "\n",
            "                            total_stockholder_equity  \n",
            "Walmart                                        77798  \n",
            "China National Petroleum                      301893  \n",
            "China Post Group                               43114  \n",
            "State Grid                                    209456  \n",
            "Hon Hai Precision Industry                     33476  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "FkB9rNiSA-tL"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.5 Using pandas methods to create boolean masks\n"
      ]
    },
    {
      "metadata": {
        "id": "qbJPh4m62E7k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "We've previously used the Python boolean operators like >, <, and **==** to create boolean masks to select subsets of data. There are also a number of pandas methods that return boolean masks that are useful for working with an exploring data.\n",
        "\n",
        "You might have noticed that for companies from the USA, the **hq_location** column contains both the city and state that the company is headquartered in:\n",
        "\n",
        "```python\n",
        ">>> usa_hqs = f500.loc[f500[\"country\"] == \"USA\", \"hq_location\"]\n",
        "\n",
        ">>> print(usa_hqs.head())\n",
        "\n",
        "    0       Bentonville, AR\n",
        "    7             Omaha, NE\n",
        "    8         Cupertino, CA\n",
        "    9            Irving, TX\n",
        "    10    San Francisco, CA\n",
        "    Name: hq_location, dtype: object\n",
        "```\n",
        "\n",
        "The two letters at the end of each of these values represent the state within the USA: AR for Arkansas, NE for Nebreska, CA for California, and TX for Texas. If we wanted to look at only companies headquartered in California, it would be useful to be able to create a boolean mask based on the text within these values.\n",
        "\n",
        "There are two pandas methods that we could use to achieve this: the [Series.str.contains()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.contains.html) method and the [Series.str.endswith()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.endswith.html) method. The Series.str.contains() method is a vectorized version of Python's in operator:\n",
        "\n",
        "```python\n",
        ">>> name = \"Michael Johnson\"\n",
        "\n",
        ">>> \"Michael\" in name\n",
        "\n",
        "    True\n",
        "\n",
        ">>> \"John\" in name\n",
        "\n",
        "    True\n",
        "\n",
        ">>> \"Eric\" in name\n",
        "\n",
        "    False\n",
        "```\n",
        "\n",
        "In contrast, **Series.str.endswith()** is a vectorized version of the Python string **str.endswith()** method , which is probably a better option for our purposes, as it will ensure that we don't get any stray matches. This is how we could go about it:\n",
        "\n",
        "\n",
        "```python\n",
        ">>> usa = f500.loc[f500[\"country\"] == \"USA\"]\n",
        "\n",
        ">>> print(usa[\"hq_location\"].head())\n",
        "\n",
        "    0       Bentonville, AR\n",
        "    7             Omaha, NE\n",
        "    8         Cupertino, CA\n",
        "    9            Irving, TX\n",
        "    10    San Francisco, CA\n",
        "    Name: hq_location, dtype: object\n",
        "\n",
        ">>> is_california = usa[\"hq_location\"].str.endswith(\"CA\")\n",
        "\n",
        ">>> print(is_california.head())\n",
        "\n",
        "    0     False\n",
        "    7     False\n",
        "    8      True\n",
        "    9     False\n",
        "    10     True\n",
        "    Name: hq_location, dtype: bool\n",
        "\n",
        ">>> california = usa[is_california]\n",
        "\n",
        ">>> print(california.iloc[:5,:3])\n",
        "\n",
        "            company  rank  revenues\n",
        "    8         Apple     9    215639\n",
        "    10     McKesson    11    198533\n",
        "    44      Chevron    45    107567\n",
        "    60  Wells Fargo    61     94176\n",
        "    64     Alphabet    65     90272\n",
        "```\n",
        "\n",
        "We won't use it in this mission, but you should also be aware of the [Series.str.startswith()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.startswith.html) method, a vectorized version of the Python string [str.startswith()](https://docs.python.org/3.6/library/stdtypes.html#str.startswith) method and can be used to create boolean masks based on the start of string values.\n",
        "\n",
        "Another pair of handy pandas methods that create boolean masks is the [Series.isnull()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.isnull.html) method and [Series.notnull()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.notnull.html) method. These return boolean masks that you can use to select either rows that contain null (or NaN) values for a certain column, or inversely those rows that don't. These can be particularly useful for identifying and exploring the rows in a dataframe.\n",
        "\n",
        "Let's see the **Series.isnull()** method in action to look at the rows that have null values in the **revenue_change** column.\n",
        "\n",
        "```python\n",
        ">>> rev_change_null = f500[f500[\"revenue_change\"].isnull()]\n",
        "\n",
        ">>> print(rev_change_null[[\"company\",\"country\",\"sector\"]])\n",
        "\n",
        "                            company  country      sector\n",
        "    90                       Uniper  Germany      Energy\n",
        "    180  Hewlett Packard Enterprise      USA  Technology\n",
        "```\n",
        "\n",
        "We can see that the two companies with missing values for the **revenue_change** column is Uniper, a German energy company; and Hewlett Parkard Enterprise, an American technology company. Let's use what we've learned to calculate ranking change for the companies that were ranked last year.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Use the **Series.notnull()** method to select all rows from **f500** that have a non-null value for the **previous_rank** column, and assign the result to **previously_ranked**\n",
        "- From the **previously_ranked** dataframe, subtract the previous_rank column from the rank column, and assign the result to **rank_change.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "r7O2wSLbHKdy",
        "outputId": "4673e989-1adb-48ec-dec6-5b4fd8ad72b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "cell_type": "code",
      "source": [
        "# put your code here\n",
        "previously_ranked = f500[f500[\"previous_rank\"].notnull()]\n",
        "\n",
        "rank_change = previously_ranked[\"previous_rank\"] - previously_ranked[\"rank\"]\n",
        "\n",
        "print(rank_change)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Walmart                                           0.0\n",
            "State Grid                                        0.0\n",
            "Sinopec Group                                     1.0\n",
            "China National Petroleum                         -1.0\n",
            "Toyota Motor                                      3.0\n",
            "Volkswagen                                        1.0\n",
            "Royal Dutch Shell                                -2.0\n",
            "Berkshire Hathaway                                3.0\n",
            "Apple                                             0.0\n",
            "Exxon Mobil                                      -4.0\n",
            "McKesson                                          1.0\n",
            "BP                                               -2.0\n",
            "UnitedHealth Group                                4.0\n",
            "CVS Health                                        4.0\n",
            "Samsung Electronics                              -2.0\n",
            "Glencore                                         -2.0\n",
            "Daimler                                          -1.0\n",
            "General Motors                                    2.0\n",
            "AT&T                                              4.0\n",
            "EXOR Group                                       -1.0\n",
            "Ford Motor                                        0.0\n",
            "Industrial & Commercial Bank of China            -7.0\n",
            "AmerisourceBergen                                 5.0\n",
            "China State Construction Engineering              3.0\n",
            "AXA                                               8.0\n",
            "Amazon.com                                       18.0\n",
            "Hon Hai Precision Industry                       -2.0\n",
            "China Construction Bank                          -6.0\n",
            "Honda Motor                                       7.0\n",
            "Total                                            -6.0\n",
            "                                                ...  \n",
            "Arrow Electronics                                -1.0\n",
            "Compal Electronics                              -58.0\n",
            "Qualcomm                                        -38.0\n",
            "Alfresa Holdings                                 31.0\n",
            "Koc Holding                                     -44.0\n",
            "Duke Energy                                     -19.0\n",
            "Michelin                                        -15.0\n",
            "Heineken Holding                                 -9.0\n",
            "Enterprise Products Partners                    -77.0\n",
            "AstraZeneca                                     -35.0\n",
            "Amgen                                            16.0\n",
            "Rabobank Group                                  -27.0\n",
            "Onex                                              9.0\n",
            "US Foods Holding                                -14.0\n",
            "Shanxi Jincheng Anthracite Coal Mining Group    -92.0\n",
            "Randstad Holding                                 17.0\n",
            "LG Display                                      -50.0\n",
            "Emirates Group                                   -8.0\n",
            "U.S. Bancorp                                      9.0\n",
            "H & M Hennes & Mauritz                            6.0\n",
            "Sodexo                                          -18.0\n",
            "GS Caltex                                       -55.0\n",
            "Ultrapar Holdings                               -13.0\n",
            "Sears Holdings                                  -64.0\n",
            "China General Technology                       -107.0\n",
            "National Grid                                   -20.0\n",
            "Telecom Italia                                  -89.0\n",
            "New China Life Insurance                        -70.0\n",
            "Wm. Morrison Supermarkets                       -61.0\n",
            "TUI                                             -32.0\n",
            "Length: 467, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A807rm_iwjrY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "v7pZdYw9IzeM"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.6 Boolean Operators\n"
      ]
    },
    {
      "metadata": {
        "id": "Ak1BmlRf2bEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Boolean indexing is a powerful tool which allows us to select or exclude parts of our data based on their values to perform analysis. There are however, some questions that we can't yet answer, like:\n",
        "\n",
        "- Which companies have over 100 billion in revenue and also have revenue growth of more than 10%?\n",
        "- What are the top 5 technology companies outside the USA?\n",
        "\n",
        "All of these questions have two or more parts that depend on the values. As an example, to answer the first question we would have to identify all the companies that have over 100 billion in revenue and also have revenue growth of more than 10%. To do this, we need to learn how to combine boolean arrays.\n",
        "\n",
        "To recap, boolean arrays are created using any of the Python standard **comparison operators**: **==** (equal), **>** (greater than), **<** (less than), **!=** (not equal).\n",
        "\n",
        "We combine boolean arrays using **boolean operators**. In Python, these boolean operators are **and**, **or**, and **not**. In pandas, the operators are slightly different:\n",
        "\n",
        "\n",
        "| pandas | Python equivalent | Meaning |\n",
        "|--------|-------------------|-------------------------------------------|\n",
        "| a & b | a and b | True if both a and b are True, else False |\n",
        "| a $|$ b | a or b | True if either a or b is True |\n",
        "| ~a | not a | True if a is False, else False |\n",
        "\n",
        "\n",
        "Let's look at how these boolean operators work across pandas series objects, using two example series objects, **a** and **b**:\n",
        "\n",
        "\n",
        "<img width=\"200\" src=\"https://drive.google.com/uc?export=view&id=1911_tZkilBFq50Qeojr8E41aTBBNQbta\">\n",
        "\n",
        "We'll start by using the & operator to perform a boolean **'and'**:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1ZdBex9EhkUA42_IzUAsbxnFU4w5-Upkg\">\n",
        "\n",
        "Let's look at what happens when we use $|$ to perform a boolean 'or':\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1TZqw-H0A-59yCkpDKrHIeVex5lHIEhEk\">\n",
        "\n",
        "Lastly, let's look at what happens when we use ~ to perform a boolean 'not':\n",
        "\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1llHLeYGNC_mtDT0qttPD9sZTJnRAwoA1\">\n",
        "\n",
        "\n",
        "Let's test our understanding of how boolean operators work with some multiple choice exercises:\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "Looking at the dataframe and code below, chose the series that matches the result of the boolean operation and assign the integer 1, 2, or 3 to **answer_1**.\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1EaFFoKazQIrAYd2tWuSSgXfePQ0nqcGm\">\n",
        "\n",
        "\n",
        "Looking at the dataframe and code below, chose the series that matches the result of the boolean operation and assign the integer 1, 2, or 3 to **answer_2.**\n",
        "\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1NgbMDdJ_oPL12pTVfCGBfv-_HX7Wl327\">\n",
        "\n",
        "Looking at the dataframe and code below, chose the series that matches the result of the boolean operation and assign the integer 1, 2, or 3 to **answer_3.**\n",
        "\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1-CZEjG5SY9Ho2alht_LjA47kKdecXA4A\">"
      ]
    },
    {
      "metadata": {
        "id": "x0b5avHEuYuk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answer_1 = 3\n",
        "answer_2 = 2\n",
        "answer_3 = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bYdP2hLwI_50"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.7 Using Boolean Operators\n"
      ]
    },
    {
      "metadata": {
        "id": "lN76DN402kK4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's look at how we use boolean operators to combine multiple boolean comparisons in practice. We'll use **f500_sel**, a small selection of our f500 dataframe:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1jR7JlIVoPzYkjy_xfpvYEaCXvikUK3qU\">\n",
        "\n",
        "\n",
        "We want to find the companies in **f500_sel** with more than 265 billion in revenue that are headquarted in China. We'll start by performing two boolean comparisons to produce two separate boolean arrays; One based on revenue, and one based on country (the revenue column is already in millions).\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1SVde3lAUEGVt69qDE7_9LHyjI80A-2_s\">\n",
        "\n",
        "We then use the & operator to combine the two boolean arrays using boolean 'and' logic:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1fefm6MA1piKONeawWn94ocbUZzb7KF4a\">\n",
        "\n",
        "\n",
        "Lastly, we use the combined boolean array to perform selection on our dataframe:\n",
        "\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1f5tAqGgDvn_faQcSK8CzSC7e3NTRII11\">\n",
        "\n",
        "\n",
        "The result give us the two companies from **f500_sel** that are both Chinese and have over 265 billion in revenue. Just like when we use a single boolean array to perform selection, when using multiple boolean arrays with boolean operators we don't need to assign things to intermediate variables. Let's look at how we can streamline the code from the example above. First, let's look at the code as one segment:\n",
        "\n",
        "```python\n",
        "cols = [\"company\", \"revenues\", \"country\"]\n",
        "final_cols = [\"company\", \"revenues\"]\n",
        "\n",
        "f500_sel = f500[cols].head()\n",
        "over_265 = f500_sel[\"revenues\"] > 265000\n",
        "china = f500_sel[\"country\"] == \"China\"\n",
        "combined = over_265 & china\n",
        "result = f500_sel.loc[combined,final_cols]\n",
        "```\n",
        "\n",
        "The first place we can optimize our code is by making our two boolean comparisons, with their boolean operator in a single line, instead of assigning them to the intermediate **china** and **over_265** variables first:\n",
        "\n",
        "\n",
        "```python\n",
        "combined = (f500_sel[\"revenues\"] > 265000) & (f500_sel[\"country\"] == \"China\")\n",
        "```\n",
        "\n",
        "We have used parentheses around each of our boolean comparisons. This is very importantâ€“ **our boolean operation will fail without parentheses**. Lastly, instead of assigning the boolean arrays to **combined**, we can insert the comparison directly into our selection:\n",
        "\n",
        "```python\n",
        "result = f500_sel.loc[(f500_sel[\"revenues\"] > 265000) & (f500_sel[\"country\"] == \"China\"), final_cols]\n",
        "```\n",
        "\n",
        "Whether to perform this final state is very much a matter of taste. As always, your decision should be driven by what will make your code more readable. Cramming everything into one line is not always the best option.\n",
        "\n",
        "Let's practice more complex selection using boolean operators\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Select from the **f500** dataframe:\n",
        "  - Companies with revenues over 100 billion and negative profits, assigning the result to **big_rev_neg_profit**.\n",
        "  - The first 5 companies in the Technology sector that are not headquartered in the USA, assigning the result to **tech_outside_usa**."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AiY27nPZ-VMc",
        "outputId": "a2be7570-df23-4c0b-d4cf-b7aac0da9518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "cell_type": "code",
      "source": [
        "# put your code here\n",
        "big_rev_neg_profit = f500[(f500[\"revenues\"] > 1000000000) & (f500[\"profits\"] < 0)]\n",
        "tech_outside_usa = f500[ (f500[\"country\"] != \"USA\") ].head()\n",
        "\n",
        "print(tech_outside_usa.head())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          rank  revenues  revenue_change  profits  assets  \\\n",
            "State Grid                   2    315199            -4.4   9571.3  489838   \n",
            "Sinopec Group                3    267518            -9.1   1257.9  310726   \n",
            "China National Petroleum     4    262573           -12.3   1867.5  585619   \n",
            "Toyota Motor                 5    254694             7.7  16899.3  437575   \n",
            "Volkswagen                   6    240264             1.5   5937.3  432116   \n",
            "\n",
            "                          profit_change              ceo  \\\n",
            "State Grid                         -6.2          Kou Wei   \n",
            "Sinopec Group                     -65.0        Wang Yupu   \n",
            "China National Petroleum          -73.7    Zhang Jianhua   \n",
            "Toyota Motor                      -12.3      Akio Toyoda   \n",
            "Volkswagen                          NaN  Matthias Muller   \n",
            "\n",
            "                                          industry                  sector  \\\n",
            "State Grid                               Utilities                  Energy   \n",
            "Sinopec Group                   Petroleum Refining                  Energy   \n",
            "China National Petroleum        Petroleum Refining                  Energy   \n",
            "Toyota Motor              Motor Vehicles and Parts  Motor Vehicles & Parts   \n",
            "Volkswagen                Motor Vehicles and Parts  Motor Vehicles & Parts   \n",
            "\n",
            "                          previous_rank  country         hq_location  \\\n",
            "State Grid                          2.0    China      Beijing, China   \n",
            "Sinopec Group                       4.0    China      Beijing, China   \n",
            "China National Petroleum            3.0    China      Beijing, China   \n",
            "Toyota Motor                        8.0    Japan       Toyota, Japan   \n",
            "Volkswagen                          7.0  Germany  Wolfsburg, Germany   \n",
            "\n",
            "                                               website  \\\n",
            "State Grid                      http://www.sgcc.com.cn   \n",
            "Sinopec Group                   http://www.sinopec.com   \n",
            "China National Petroleum        http://www.cnpc.com.cn   \n",
            "Toyota Motor              http://www.toyota-global.com   \n",
            "Volkswagen                   http://www.volkswagen.com   \n",
            "\n",
            "                          years_on_global_500_list  employees  \\\n",
            "State Grid                                      17     926067   \n",
            "Sinopec Group                                   19     713288   \n",
            "China National Petroleum                        17    1512048   \n",
            "Toyota Motor                                    23     364445   \n",
            "Volkswagen                                      23     626715   \n",
            "\n",
            "                          total_stockholder_equity  \n",
            "State Grid                                  209456  \n",
            "Sinopec Group                               106523  \n",
            "China National Petroleum                    301893  \n",
            "Toyota Motor                                157210  \n",
            "Volkswagen                                   97753  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Ow84417-A5Ph"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.8 Pandas Index Alignment\n"
      ]
    },
    {
      "metadata": {
        "id": "1NTJNTo32tT3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "So far, we've only seen examples where the dataframe and series objects we're working with have matching index labels. One of the most powerful aspects of pandas is that almost every operation will **align on the index labels**. Let's look at an exampleâ€“ below we have a dataframe **food** and a **series** colors:\n",
        "\n",
        "<img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1_LAUprnXe3BYUgUg2r5fS2kfPpoTtdgt\">\n",
        "\n",
        "Both the **food** dataframe and the **colors** series have the same index labels, however they are in totally different orders. As an example, the first row of **food** has the index label **tomato**, and the first item of **colors** has the index label **corn**.\n",
        "\n",
        "If we wanted to add **colors** as a new column in our **food** dataframe, we can use the following code:\n",
        "\n",
        "```python\n",
        "food[\"color\"] = colors\n",
        "```\n",
        "\n",
        "When we do this, pandas will ignore the order of the colors series, and align on the index labels:\n",
        "\n",
        "<img width=\"350\" src=\"https://drive.google.com/uc?export=view&id=1zD-HqxfZ8yUj_4pNrbQasrnASTX0zhQE\">\n",
        "\n",
        "The result of our code operation is the dataframe below:\n",
        "\n",
        "<img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1hDfSi-D5sJf788MlGOI63vmAlLYrVIYU\">\n",
        "\n",
        "\n",
        "We can see that pandas has done all the hard work for us, and we don't have to worry about the fact that our series and dataframe were ordered differently. Let's look at another example. Say we had the series **alt_name** below:\n",
        "\n",
        "<img width=\"200\" src=\"https://drive.google.com/uc?export=view&id=1jMt7P6e0d7X8yaE2kLm0gPzaCxQtS30F\">\n",
        "\n",
        "\n",
        "The **alt_name** series only has three items. The first item, with index label **arugula** doesn't have a corresponding row in the **food** dataframe, where the other two do. Let's see what happens when we assign this as a new column:\n",
        "\n",
        "```python\n",
        "food[\"alt_name\"] = alt_name\n",
        "```\n",
        "\n",
        "<img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1Vs-aLaUmDmdqUtDPt6_Eh7B3T6d3Wvhx\">\n",
        "\n",
        "\n",
        "In this scenario, pandas:\n",
        "\n",
        "- Discards any items that have an index that doesn't match the dataframe.\n",
        "- Aligns on the index labels for the values that do match the dataframe.\n",
        "- Fills any remaining rows with **NaN**\n",
        "\n",
        "If we assign a new column with no matching index labels, pandas follows the same three steps above, but as there are no matching labels, all rows in the new column will be **NaN** values.\n",
        "\n",
        "The pandas library will align on index at every opportunity - this makes working with data from different sources, or working with data when you have removed, added, or reordered rows much easier than it would be otherwise. This works whether your index labels are strings or integers - as long as you haven't made modifications to the index labels, you can use index alignment to our advantage.\n",
        "\n",
        "Let's practice this using our Fortune 500 data.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "Earlier, we created the **rank_change** series by performing vectorized subtraction only on rows without null values. We have included the code again as a reminder.\n",
        "\n",
        "- Assign the values in the **rank_change** to a new column in the **f500** dataframe, **\"rank_change\".**\n",
        "- Once you have run your code, use the variable inspector to look at the **f500** dataframe and observe how the new column aligns with the existing data."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KxTo6msfCcF7",
        "outputId": "22cd46b1-5a88-44d0-a918-9ad5f0222d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "cell_type": "code",
      "source": [
        "previously_ranked = f500[f500[\"previous_rank\"].notnull()]\n",
        "rank_change = previously_ranked[\"previous_rank\"] - previously_ranked[\"rank\"]\n",
        "\n",
        "# put your code here\n",
        "\n",
        "#Add column\n",
        "f500[\"rank_change\"] = rank_change\n",
        "\n",
        "print(f500.head())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          rank  revenues  revenue_change  profits  assets  \\\n",
            "Walmart                      1    485873             0.8  13643.0  198825   \n",
            "State Grid                   2    315199            -4.4   9571.3  489838   \n",
            "Sinopec Group                3    267518            -9.1   1257.9  310726   \n",
            "China National Petroleum     4    262573           -12.3   1867.5  585619   \n",
            "Toyota Motor                 5    254694             7.7  16899.3  437575   \n",
            "\n",
            "                          profit_change                  ceo  \\\n",
            "Walmart                            -7.2  C. Douglas McMillon   \n",
            "State Grid                         -6.2              Kou Wei   \n",
            "Sinopec Group                     -65.0            Wang Yupu   \n",
            "China National Petroleum          -73.7        Zhang Jianhua   \n",
            "Toyota Motor                      -12.3          Akio Toyoda   \n",
            "\n",
            "                                          industry                  sector  \\\n",
            "Walmart                      General Merchandisers               Retailing   \n",
            "State Grid                               Utilities                  Energy   \n",
            "Sinopec Group                   Petroleum Refining                  Energy   \n",
            "China National Petroleum        Petroleum Refining                  Energy   \n",
            "Toyota Motor              Motor Vehicles and Parts  Motor Vehicles & Parts   \n",
            "\n",
            "                          previous_rank country      hq_location  \\\n",
            "Walmart                             1.0     USA  Bentonville, AR   \n",
            "State Grid                          2.0   China   Beijing, China   \n",
            "Sinopec Group                       4.0   China   Beijing, China   \n",
            "China National Petroleum            3.0   China   Beijing, China   \n",
            "Toyota Motor                        8.0   Japan    Toyota, Japan   \n",
            "\n",
            "                                               website  \\\n",
            "Walmart                         http://www.walmart.com   \n",
            "State Grid                      http://www.sgcc.com.cn   \n",
            "Sinopec Group                   http://www.sinopec.com   \n",
            "China National Petroleum        http://www.cnpc.com.cn   \n",
            "Toyota Motor              http://www.toyota-global.com   \n",
            "\n",
            "                          years_on_global_500_list  employees  \\\n",
            "Walmart                                         23    2300000   \n",
            "State Grid                                      17     926067   \n",
            "Sinopec Group                                   19     713288   \n",
            "China National Petroleum                        17    1512048   \n",
            "Toyota Motor                                    23     364445   \n",
            "\n",
            "                          total_stockholder_equity  rank_change  \n",
            "Walmart                                      77798          0.0  \n",
            "State Grid                                  209456          0.0  \n",
            "Sinopec Group                               106523          1.0  \n",
            "China National Petroleum                    301893         -1.0  \n",
            "Toyota Motor                                157210          3.0  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-YKQxivqGGGJ"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.9 Using Loops with pandas\n"
      ]
    },
    {
      "metadata": {
        "id": "XW-AT1QN2yGU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "So far, we've explicitly avoided doing anything with loops using pandas. Because one of the key benefits of pandas is that it has vectorized methods to work with data more efficiently, we want to avoid using loops wherever we can.\n",
        "\n",
        "As an illustration, let's look at one common pattern that you might be tempted to use a loop for, and how we can use a vectorized operation to replace it. Let's try and replace all of the values in the column **B** a dataframe:\n",
        "\n",
        "```python\n",
        ">>> print(df)\n",
        "\n",
        "       A  B  C\n",
        "    x  6  1  0\n",
        "    y  1  8  8\n",
        "    z  3  8  7\n",
        "\n",
        ">>> for row in df:\n",
        "        if row[\"B\"] == 8:\n",
        "            row[\"B\"] = 99\n",
        "\n",
        "    ---------------------------------------------------\n",
        "    TypeError                                 Traceback\n",
        "    <ipython-input-17-baf1fd443d29> in module()\n",
        "          1 for row in df:\n",
        "    ----> 2     if row[\"B\"] == 8:\n",
        "          3         row[\"B\"] = 99\n",
        "\n",
        "    TypeError: string indices must be integers\n",
        "</ipython-input-17-baf1fd443d29>\n",
        "```\n",
        "\n",
        "In this code, we attempted to loop over every row of the dataframe, check the value for a particular column, and if it matches our check, we change it. Unfortunately, our code produced an error.\n",
        "\n",
        "When you attempt to loop over a dataframe, it returns the column index labels, rather than the rows as we might expect. There are pandas methods to help loop over dataframes, but they should be only used as a last resort, and can almost always be avoided (we'll learn about those methods in a later course).\n",
        "\n",
        "```python\n",
        ">>> print(df)\n",
        "\n",
        "       A  B  C\n",
        "    x  6  1  0\n",
        "    y  1  8  8\n",
        "    z  3  8  7\n",
        "\n",
        ">>> for i in df:\n",
        "        print(i)\n",
        "\n",
        "    A\n",
        "    B\n",
        "    C\n",
        "```\n",
        "\n",
        "Instead of trying to use loops, we can perform the same operation quickly and easily using vectorized operations:\n",
        "\n",
        "```python\n",
        ">>> df.loc[df[\"B\"] == 8, \"B\"] = 99\n",
        "\n",
        ">>> print(df)\n",
        "\n",
        "       A   B  C\n",
        "    x  6   1  0\n",
        "    y  1  99  8\n",
        "    z  3  99  7\n",
        "```\n",
        "\n",
        "One scenario where it is useful to use loops with pandas is when we are performing aggregation. Aggregation is where we apply a statistical operation to groups of our data. Let's say that we wanted to work out what the average revenue was for each country in the data set. Our process might look like this:\n",
        "\n",
        "- Identify each unique country in the data set.\n",
        "- For each country:\n",
        "  - Select only the rows corresponding to that country.\n",
        "  - Calculate the average revenue for those rows.\n",
        "\n",
        "In this process, we can use a loop to iterate over the countries. We'll still use vectorized operations to select the right rows and calculate the means, so our calculation remains fast. To identify the unique countries, we can use the [Series.unique() method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.unique.html). This method returns an array of unique values from any series. Once we have that, we can loop over that array and perform our operation. We'll use a dictionary to store the results. Here's what that looks like:\n",
        "\n",
        "\n",
        "```python\n",
        "# Create an empty dictionary to store the results\n",
        "avg_rev_by_country = {}\n",
        "\n",
        "# Create an array of unique countries\n",
        "countries = f500[\"country\"].unique()\n",
        "\n",
        "# Use a for loop to iterate over the countries\n",
        "for c in countries:\n",
        "    # Use boolean comparison to select only rows that\n",
        "    # correspond to a specific country\n",
        "    selected_rows = f500[f500[\"country\"] == c]\n",
        "    # Calculate the mean average revenue for just those rows\n",
        "    mean = selected_rows[\"revenues\"].mean()\n",
        "    # Assign the mean value to the dictionary, using the\n",
        "    # country name as the key\n",
        "    avg_rev_by_country[c] = mean\n",
        "```\n",
        "\n",
        "\n",
        "The resulting dictionary is below (we've shown just the first few keys):\n",
        "\n",
        "```python\n",
        "{'Australia': 33688.71428571428,\n",
        " 'Belgium': 45905.0,\n",
        " 'Brazil': 52024.57142857143,\n",
        " 'Britain': 51588.708333333336,\n",
        " 'Canada': 31848.0,\n",
        " 'China': 55397.880733944956,\n",
        " 'Denmark': 35464.0,\n",
        " ...\n",
        " }\n",
        "```\n",
        "\n",
        "We'll practice this pattern to calculate the company that employs the most people in each country. To do this extra step, we'll use the [DataFrame.sort_values()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html) method to sort our dataframe so we can then select the first row which will give us our largest value.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "In this exercise, we're going to produce the following dictionary of the top employer in each country:\n",
        "\n",
        "```python\n",
        "{'Australia': 'Wesfarmers',\n",
        " 'Belgium': 'Anheuser-Busch InBev',\n",
        " 'Brazil': 'JBS',\n",
        " ...\n",
        " 'U.A.E': 'Emirates Group',\n",
        " 'USA': 'Walmart',\n",
        " 'Venezuela': 'Mercantil Servicios Financieros'}\n",
        "```\n",
        "\n",
        "- Read the documentation for the [DataFrame.sort_values() method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html) to familiarize yourself with the syntax. You will need to use only the **by** and **ascending** parameters to complete this exercise.\n",
        "- Create an empty dictionary, **top_employer_by_country** to store the results of the exercise.\n",
        "- Use the **Series.unique()** method to create an array of unique values from the **country** column.\n",
        "- Use a for loop to iterate over the array unique countries, and in each iteration:\n",
        "  - Select only the rows that have a country name equal to the current iteration.\n",
        "  - Use **DataFrame.sort_values()** to sort those rows by the **employees** column in descending order.\n",
        "  - Select the first row from the sorted dataframe.\n",
        "  - Extract the company name from the index label **company** from the first row.\n",
        "  - Assign the results to the **top_employer_by_country** dictionary, using the country name as the key, and the company name as the value.\n",
        "- When you have run your code, use the variable inspector to view the top employer for each country.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "19buYA9i0b3H",
        "colab_type": "code",
        "outputId": "4d593c52-0dea-4874-b53a-2d357b9ee3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "f500.index[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Walmart'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "RSJw37Z62alC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bu6ehekV2Zuk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QgwfYiJnLtyq",
        "outputId": "ae732a8d-47b5-4892-a3ef-24c503930d67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# put your code here\n",
        "# can you do it using just one code line?\n",
        "\n",
        "top_employer_by_country = {}\n",
        "\n",
        "## get the countries\n",
        "countries = f500[\"country\"].unique()\n",
        "for country in countries:\n",
        "  selected =  f500[f500[\"country\"] == country]\n",
        "  #sort by employees\n",
        "  sorted_df = selected.sort_values(by=\"employees\", ascending=False)\n",
        "  ## get the first company and its name\n",
        "  company = f500.index[sorted_df.iloc[0,0]]\n",
        "  top_employer_by_country[country] = company\n",
        "  \n",
        "print(top_employer_by_country)\n",
        "\n",
        "\n",
        "#in one line\n",
        "\n",
        "top_employer_by_country_one_line = { c: f500.index[f500[f500[\"country\"] == c].sort_values(by=\"employees\", ascending=False).iloc[0,0]] for c in f500[\"country\"].unique() } \n",
        "\n",
        "print(top_employer_by_country_one_line)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'USA': 'State Grid', 'China': 'Toyota Motor', 'Japan': 'Volkswagen', 'Germany': 'Royal Dutch Shell', 'Netherlands': 'Ford Motor', 'Britain': 'Schlumberger', 'South Korea': 'Glencore', 'Switzerland': 'Alphabet', 'France': 'Suning Commerce Group', 'Taiwan': 'China Construction Bank', 'Singapore': 'Arrow Electronics', 'Italy': 'Centrica', 'Russia': 'Nestle', 'Spain': 'Citigroup', 'Brazil': 'PTT', 'Mexico': 'Korea Electric Power', 'Luxembourg': 'Renault', 'India': 'Woolworths', 'Malaysia': 'Tokyo Electric Power', 'Thailand': 'Tokio Marine Holdings', 'Australia': 'Sinopharm', 'Belgium': 'Statoil', 'Norway': 'POSCO', 'Canada': 'Mitsubishi Heavy Industries', 'Ireland': 'Repsol', 'Indonesia': 'Magna International', 'Denmark': 'SABIC', 'Saudi Arabia': 'Bouygues', 'Sweden': 'Aflac', 'Finland': 'Enbridge', 'Venezuela': 'SAP', 'Turkey': 'Progressive', 'U.A.E': 'U.S. Bancorp', 'Israel': 'New China Life Insurance'}\n",
            "{'USA': 'State Grid', 'China': 'Toyota Motor', 'Japan': 'Volkswagen', 'Germany': 'Royal Dutch Shell', 'Netherlands': 'Ford Motor', 'Britain': 'Schlumberger', 'South Korea': 'Glencore', 'Switzerland': 'Alphabet', 'France': 'Suning Commerce Group', 'Taiwan': 'China Construction Bank', 'Singapore': 'Arrow Electronics', 'Italy': 'Centrica', 'Russia': 'Nestle', 'Spain': 'Citigroup', 'Brazil': 'PTT', 'Mexico': 'Korea Electric Power', 'Luxembourg': 'Renault', 'India': 'Woolworths', 'Malaysia': 'Tokyo Electric Power', 'Thailand': 'Tokio Marine Holdings', 'Australia': 'Sinopharm', 'Belgium': 'Statoil', 'Norway': 'POSCO', 'Canada': 'Mitsubishi Heavy Industries', 'Ireland': 'Repsol', 'Indonesia': 'Magna International', 'Denmark': 'SABIC', 'Saudi Arabia': 'Bouygues', 'Sweden': 'Aflac', 'Finland': 'Enbridge', 'Venezuela': 'SAP', 'Turkey': 'Progressive', 'U.A.E': 'U.S. Bancorp', 'Israel': 'New China Life Insurance'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DonEC76kNRy8"
      },
      "cell_type": "markdown",
      "source": [
        "## 2 Challenge: Calculating Return on Assets by Sector\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2fljK-Kz3QAB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now it's time for a challenge to bring everything together! In this challenge we're going to add a new column to our dataframe, and then perform some aggregation using that new column.\n",
        "\n",
        "The column we create is going to contain a metric called [return on assets (ROA)](https://www.inc.com/encyclopedia/return-on-assets-roa.html). ROA is a business-specific metric which inicates a companies ability to make profit using their available assets.\n",
        "\n",
        "$\n",
        "\\textrm{return on assets} = \\frac{profits}{assets}\n",
        "$\n",
        "\n",
        "Once we've created the new column, we'll aggregate by sector, and find the company with the highest ROA from each sector. Like previous challenges, we'll provide some guidance in the hints, but try to complete it without them if you can.\n",
        "\n",
        "Don't be discouraged if this challenge takes a few attempts to get correct. Working iteratively is a great way to work, and this challenge is more difficult than exercises you have previously completed.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "- Create a new column **roa** in the **f500** dataframe, containing the return on assets metric for each company.\n",
        "- Aggregate the data by the **sector** column, and create a dictionary **top_roa_by_sector**, with:\n",
        "  - Dictionary keys with the sector name.\n",
        "  - Dictionary values with the company name with the highest ROA value from that sector.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ih-EUDaMOLtz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here\n",
        "f500['roa'] = f500['profits']/f500['assets']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gICKAdkz6mp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ea97b206-5669-44b3-cc47-5095ed3c59ca"
      },
      "cell_type": "code",
      "source": [
        "f500['roa'].head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Walmart                     0.068618\n",
              "State Grid                  0.019540\n",
              "Sinopec Group               0.004048\n",
              "China National Petroleum    0.003189\n",
              "Toyota Motor                0.038620\n",
              "Name: roa, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "X3Tf6DJf0Bqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top_roa_by_sector = {}\n",
        "\n",
        "## get the countries\n",
        "sectors = f500[\"sector\"].unique()\n",
        "for sector in sectors:\n",
        "  selected =  f500[f500[\"sector\"] == sector]\n",
        "  #sort by roa\n",
        "  sorted_df = selected.sort_values(by=\"roa\", ascending=False)\n",
        "  ## get the first company and its name\n",
        "  roa_index = len(f500.columns)-1\n",
        "  roa = sorted_df.iloc[0,17]\n",
        "  top_roa_by_sector[sector] = roa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QKm97PB51CT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "acd0e113-fd81-4cc6-a4a2-45cabf85c58a"
      },
      "cell_type": "code",
      "source": [
        "top_roa_by_sector"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Aerospace & Defense': 0.11090658076392085,\n",
              " 'Apparel': 0.17573378201532996,\n",
              " 'Business Services': 0.07506337433104873,\n",
              " 'Chemicals': 0.16363791485368143,\n",
              " 'Energy': 0.1233215891143239,\n",
              " 'Engineering & Construction': 0.06573367084405345,\n",
              " 'Financials': 0.038775621965872815,\n",
              " 'Food & Drug Stores': 0.11599289967934036,\n",
              " 'Food, Beverages & Tobacco': 0.18905864155653848,\n",
              " 'Health Care': 0.23695526264984115,\n",
              " 'Hotels, Restaurants & Leisure': 0.15106046931407943,\n",
              " 'Household Products': 0.09632847156875923,\n",
              " 'Industrials': 0.1534674527441804,\n",
              " 'Materials': 0.04125450180072029,\n",
              " 'Media': 0.10203948583660209,\n",
              " 'Motor Vehicles & Parts': 0.10509800758247964,\n",
              " 'Retailing': 0.2052523171987642,\n",
              " 'Technology': 0.19951962734727544,\n",
              " 'Telecommunications': 0.0897337388613201,\n",
              " 'Transportation': 0.08530851914710989,\n",
              " 'Wholesalers': 0.08315701422034148}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jmm3MDc8OYFy"
      },
      "cell_type": "markdown",
      "source": [
        "In this lesson, we learned how to:\n",
        "\n",
        "- Select columns, rows and individual items using their integer location.\n",
        "- Use **pd.read_csv()** to read CSV files in pandas.\n",
        "- Work with integer axis labels.\n",
        "- How to use pandas methods to produce boolean arrays.\n",
        "- Use boolean operators to combine boolean comparisons to perform more complex analysis.\n",
        "- Use index labels to align data.\n",
        "- Use aggregation to perform advanced analysis using loops.\n",
        "\n",
        "In the next lesson, we'll learn techniques to use when performing data cleaning to prepare a messy data set."
      ]
    }
  ]
}