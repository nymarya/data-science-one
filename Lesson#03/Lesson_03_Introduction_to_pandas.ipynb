{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson_03_Introduction_to_pandas.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "woIhBlBupowm",
        "bCQYczBFsxN5",
        "qozEt3qdv4Zc",
        "H64LApNI2vKJ",
        "5NajzEqj6Usm",
        "OtV3NQPnAgM5",
        "6hN_9QIlH7ey",
        "F8871OlQNvYW",
        "SJNwnlxMS8fc",
        "X0sKBpdxVMM_",
        "wF256cCCnWVa",
        "wjtwE9KKrF5Z"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "Oid5l5CVmnS0",
        "toc-hr-collapsed": true
      },
      "cell_type": "markdown",
      "source": [
        "## 1 Introduction to Pandas"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "woIhBlBupowm"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 Understanding pandas\n"
      ]
    },
    {
      "metadata": {
        "id": "x2ouv1i2r3tu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pandas is a popular Python package for data science, and with good reason: it offers powerful, expressive and flexible data structures that make data manipulation and analysis easy, among many other things.\n",
        "\n",
        "In this lesson, we'll learn:\n",
        "\n",
        "- about the two core pandas types: dataframes and series\n",
        "- how to select data using row and column labels\n",
        "- a variety of methods for exploring data with pandas\n",
        "- how to assign data using various techniques in pandas\n",
        "- how to use boolean indexing with pandas for selection and assignment\n",
        "\n",
        "We'll be working with data set from [Fortune](http://fortune.com/) magazine's [Global 500](https://en.wikipedia.org/wiki/Fortune_Global_500) list 2017, which ranks the top 500 corporations worldwide by revenue. The dataset we'll be using was originally compiled [here](https://data.world/chasewillden/fortune-500-companies-2017), however we have modified the original data set into a more accessible format.\n",
        "\n",
        "<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1vWtPGbbxR7Mn2xHg_KMa3MOKSqs05uyE\">\n",
        "\n",
        "\n",
        "The dataset is a CSV file called **f500.csv**. Here is a data dictionary for some of the columns in the CSV:\n",
        "\n",
        "- **company** - The Name of the company.\n",
        "- **rank** - The Global 500 rank for the company.\n",
        "- **revenues** - The company's total revenues for the fiscal year, in millions of dollars (USD).\n",
        "- **revenue_change** - The percentage change in revenue between the current and prior fiscal years.\n",
        "- **profits** - Net income for the fiscal year, in millions of dollars (USD).\n",
        "- **ceo** - The company's Chief Executive Officer.\n",
        "- **industry** - The industry in which the company operates.\n",
        "- **sector** - The sector in which the company operates.\n",
        "- **previous_rank** - The Global 500 rank for the company for the prior year.\n",
        "- **country** - The Country in which the company is headquartered.\n",
        "- **hq_location** - The City and Country, (or City and State for the USA) where the company is headquarted.\n",
        "- **employees** - Total employees (full-time equivalent, if available) at fiscal year-end.\n",
        "\n",
        "\n",
        "The import convention for pandas is:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "```\n",
        "\n",
        "We have already imported pandas and used the [pandas.read_csv()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function to read the CSV into a pandas object and assign it to the variable name f500. In the next mission we'll learn about **read_csv()**, but for now all you need to know is that it handles reading and parsing most CSV files automatically.\n",
        "\n",
        "Pandas objects have a **.shape** attribute which returns a tuple representing the dimensions of each axis of the object. We'll use that and the Python's **type()** function to inspect the f500 pandas object.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "1. Use Python's **type()** function to assign the type of **f500** to **f500_type.**\n",
        "2. Use the **DataFrame.shape** attribute to assign the shape of **f500** to **f500_shape.**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Hn9JxP26rgAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "c6bfcb97-656e-43d7-be34-8679655466d7"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# set company name as index and remove column name\n",
        "f500 = pd.read_csv(\"f500.csv\", index_col=0) \n",
        "f500.index.name = None\n",
        "\n",
        "# put your code here\n",
        "print(type(f500))\n",
        "print(f500.shape)\n",
        "print(f500.dtypes)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "(500, 16)\n",
            "rank                          int64\n",
            "revenues                      int64\n",
            "revenue_change              float64\n",
            "profits                     float64\n",
            "assets                        int64\n",
            "profit_change               float64\n",
            "ceo                          object\n",
            "industry                     object\n",
            "sector                       object\n",
            "previous_rank                 int64\n",
            "country                      object\n",
            "hq_location                  object\n",
            "website                      object\n",
            "years_on_global_500_list      int64\n",
            "employees                     int64\n",
            "total_stockholder_equity      int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bCQYczBFsxN5"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 Introducing DataFrames\n"
      ]
    },
    {
      "metadata": {
        "id": "hcn2UhRC0tRF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "The code we wrote in the previous screen let us know that our data has 500 rows and 16 columns, and is stored as a [pandas.core.frame.DataFrame object](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame). More commonly referred to as **pandas.DataFrame()** objects, or just **dataframes**, the type is the primary pandas data structure. Dataframes are two dimensional pandas objects.\n",
        "\n",
        "We'll learn about the second pandas data structure, series, later in this lesson, but first, let's look at the anatomy of a dataframe, using a selection of our Fortune 500 data:\n",
        "\n",
        "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1lUAxPbqauhiMPdWCAM2oPOy0vsmvWtYy\">\n",
        "\n",
        "There are three key things we can observe immediately:\n",
        "\n",
        "- In Red: Just like a 2D ndarray, there are two axes, however each axis of a dataframe has a specific name. The first axis is called **index**, and the second axis is called **columns.**\n",
        "- In Blue: Our axis values have string **labels**, not just numeric locations.\n",
        "- In Green: Our dataframe contains columns with **multiple dtypes**: integer, float, and string.\n",
        "\n",
        "We can use the [DataFrame.dtypes](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dtypes.html#pandas.DataFrame.dtypes) attribute to return information about the types of each column. Let's see what this would return for our selection of data above:\n",
        "\n",
        "```python\n",
        ">>> f500_selection.dtypes\n",
        "\n",
        "    rank          int64\n",
        "    revenues      int64\n",
        "    profits     float64\n",
        "    country      object\n",
        "    dtype: object\n",
        "```\n",
        "\n",
        "We can see three different data types (dtypes), which correspond to what we observed by looking at the data:\n",
        "\n",
        "- int64\n",
        "- float64\n",
        "- object\n",
        "\n",
        "\n",
        "\n",
        "When we import data, pandas will attempt to guess the correct dtype for each column. Generally, pandas does a pretty good job with this, which means we don't need to worry about specifying dtypes every time we start to work with data. Later in this course, we'll look at how to change the dtype of a column.\n",
        "\n",
        "Next, let's learn a few handy methods we can use to get some high-level information about our dataframe:\n",
        "\n",
        "- If we wanted to view the first few rows of our dataframe, we can use the [DataFrame.head()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html) method, which returns the first 5 rows of our dataframe. The **DataFrame.head()** method also accepts an optional integer parameter which specified the number of rows. We could use **f500.head(10)** to return the first 10 rows of our **f500 dataframe**.\n",
        "- Similar in function to **DataFrame.head()**, we can use the [DataFrame.tail()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tail.html) method, to shows us the last rows of our dataframe. The **DataFrame.tail()** method accepts an optional integer parameter to specify the number of rows, defaulting to 5.\n",
        "- If we wanted to get an overview of all the dtypes used in our dataframe, along with its shape and some extra information, we could use the [DataFrame.info()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html#pandas.DataFrame.info) method. Note that **DataFrame.info()** prints the information, rather than returning it, so we can't assign it to a variable.\n",
        "\n",
        "Let's practice using these three new methods. Just like in the previous missions, the f500 variable we created in the previous section is available to you here.\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "1. Using the links above to the documentation if you need to, use the three methods we just learned about to learn more about the **f500** dataframe:\n",
        "\n",
        "  - Use the **head()** method to select the first 6 rows and assign the result to **f500_head**.\n",
        "  - Use the **tail()** method to select the last 8 rows and assign the result to **f500_tail.**\n",
        "  - Use the **info()** method to display information about the dataframe.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JW4ZDCUFs0X8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2358
        },
        "outputId": "ecc79c3a-fae2-4027-d636-083269b2eac3"
      },
      "cell_type": "code",
      "source": [
        "# put your code here\n",
        "f500_head = f500.head()\n",
        "f500_tail = f500.tail()\n",
        "\n",
        "print(f500_head)\n",
        "print(\"\\nTAIL\\n\")\n",
        "print(f500_tail)\n",
        "print(\"\\nINFO\\n\")\n",
        "print(f500.info())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          rank  revenues  revenue_change  profits  assets  \\\n",
            "Walmart                      1    485873             0.8  13643.0  198825   \n",
            "State Grid                   2    315199            -4.4   9571.3  489838   \n",
            "Sinopec Group                3    267518            -9.1   1257.9  310726   \n",
            "China National Petroleum     4    262573           -12.3   1867.5  585619   \n",
            "Toyota Motor                 5    254694             7.7  16899.3  437575   \n",
            "\n",
            "                          profit_change                  ceo  \\\n",
            "Walmart                            -7.2  C. Douglas McMillon   \n",
            "State Grid                         -6.2              Kou Wei   \n",
            "Sinopec Group                     -65.0            Wang Yupu   \n",
            "China National Petroleum          -73.7        Zhang Jianhua   \n",
            "Toyota Motor                      -12.3          Akio Toyoda   \n",
            "\n",
            "                                          industry                  sector  \\\n",
            "Walmart                      General Merchandisers               Retailing   \n",
            "State Grid                               Utilities                  Energy   \n",
            "Sinopec Group                   Petroleum Refining                  Energy   \n",
            "China National Petroleum        Petroleum Refining                  Energy   \n",
            "Toyota Motor              Motor Vehicles and Parts  Motor Vehicles & Parts   \n",
            "\n",
            "                          previous_rank country      hq_location  \\\n",
            "Walmart                               1     USA  Bentonville, AR   \n",
            "State Grid                            2   China   Beijing, China   \n",
            "Sinopec Group                         4   China   Beijing, China   \n",
            "China National Petroleum              3   China   Beijing, China   \n",
            "Toyota Motor                          8   Japan    Toyota, Japan   \n",
            "\n",
            "                                               website  \\\n",
            "Walmart                         http://www.walmart.com   \n",
            "State Grid                      http://www.sgcc.com.cn   \n",
            "Sinopec Group                   http://www.sinopec.com   \n",
            "China National Petroleum        http://www.cnpc.com.cn   \n",
            "Toyota Motor              http://www.toyota-global.com   \n",
            "\n",
            "                          years_on_global_500_list  employees  \\\n",
            "Walmart                                         23    2300000   \n",
            "State Grid                                      17     926067   \n",
            "Sinopec Group                                   19     713288   \n",
            "China National Petroleum                        17    1512048   \n",
            "Toyota Motor                                    23     364445   \n",
            "\n",
            "                          total_stockholder_equity  \n",
            "Walmart                                      77798  \n",
            "State Grid                                  209456  \n",
            "Sinopec Group                               106523  \n",
            "China National Petroleum                    301893  \n",
            "Toyota Motor                                157210  \n",
            "\n",
            "TAIL\n",
            "\n",
            "                                rank  revenues  revenue_change  profits  \\\n",
            "Teva Pharmaceutical Industries   496     21903            11.5    329.0   \n",
            "New China Life Insurance         497     21796           -13.3    743.9   \n",
            "Wm. Morrison Supermarkets        498     21741           -11.3    406.4   \n",
            "TUI                              499     21655            -5.5   1151.7   \n",
            "AutoNation                       500     21609             3.6    430.5   \n",
            "\n",
            "                                assets  profit_change                 ceo  \\\n",
            "Teva Pharmaceutical Industries   92890          -79.3   Yitzhak Peterburg   \n",
            "New China Life Insurance        100609          -45.6            Wan Feng   \n",
            "Wm. Morrison Supermarkets        11630           20.4      David T. Potts   \n",
            "TUI                              16247          195.5   Friedrich Joussen   \n",
            "AutoNation                       10060           -2.7  Michael J. Jackson   \n",
            "\n",
            "                                                       industry  \\\n",
            "Teva Pharmaceutical Industries                  Pharmaceuticals   \n",
            "New China Life Insurance        Insurance: Life, Health (stock)   \n",
            "Wm. Morrison Supermarkets                  Food and Drug Stores   \n",
            "TUI                                             Travel Services   \n",
            "AutoNation                                  Specialty Retailers   \n",
            "\n",
            "                                            sector  previous_rank  country  \\\n",
            "Teva Pharmaceutical Industries         Health Care              0   Israel   \n",
            "New China Life Insurance                Financials            427    China   \n",
            "Wm. Morrison Supermarkets       Food & Drug Stores            437  Britain   \n",
            "TUI                              Business Services            467  Germany   \n",
            "AutoNation                               Retailing              0      USA   \n",
            "\n",
            "                                         hq_location  \\\n",
            "Teva Pharmaceutical Industries  Petach Tikva, Israel   \n",
            "New China Life Insurance              Beijing, China   \n",
            "Wm. Morrison Supermarkets          Bradford, Britain   \n",
            "TUI                                 Hanover, Germany   \n",
            "AutoNation                       Fort Lauderdale, FL   \n",
            "\n",
            "                                                    website  \\\n",
            "Teva Pharmaceutical Industries     http://www.tevapharm.com   \n",
            "New China Life Insurance        http://www.newchinalife.com   \n",
            "Wm. Morrison Supermarkets          http://www.morrisons.com   \n",
            "TUI                                 http://www.tuigroup.com   \n",
            "AutoNation                        http://www.autonation.com   \n",
            "\n",
            "                                years_on_global_500_list  employees  \\\n",
            "Teva Pharmaceutical Industries                         1      56960   \n",
            "New China Life Insurance                               2      54378   \n",
            "Wm. Morrison Supermarkets                             13      77210   \n",
            "TUI                                                   23      66779   \n",
            "AutoNation                                            12      26000   \n",
            "\n",
            "                                total_stockholder_equity  \n",
            "Teva Pharmaceutical Industries                     33337  \n",
            "New China Life Insurance                            8507  \n",
            "Wm. Morrison Supermarkets                           5111  \n",
            "TUI                                                 3006  \n",
            "AutoNation                                          2310  \n",
            "\n",
            "INFO\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 500 entries, Walmart to AutoNation\n",
            "Data columns (total 16 columns):\n",
            "rank                        500 non-null int64\n",
            "revenues                    500 non-null int64\n",
            "revenue_change              498 non-null float64\n",
            "profits                     499 non-null float64\n",
            "assets                      500 non-null int64\n",
            "profit_change               436 non-null float64\n",
            "ceo                         500 non-null object\n",
            "industry                    500 non-null object\n",
            "sector                      500 non-null object\n",
            "previous_rank               500 non-null int64\n",
            "country                     500 non-null object\n",
            "hq_location                 500 non-null object\n",
            "website                     500 non-null object\n",
            "years_on_global_500_list    500 non-null int64\n",
            "employees                   500 non-null int64\n",
            "total_stockholder_equity    500 non-null int64\n",
            "dtypes: float64(3), int64(7), object(6)\n",
            "memory usage: 66.4+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cS5k8jjfYFr0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "fa4d90f3-407a-4d63-c6f3-a3521f132b0c"
      },
      "cell_type": "code",
      "source": [
        "print(f500.describe())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             rank       revenues  revenue_change       profits        assets  \\\n",
            "count  500.000000     500.000000      498.000000    499.000000  5.000000e+02   \n",
            "mean   250.500000   55416.358000        4.538353   3055.203206  2.436323e+05   \n",
            "std    144.481833   45725.478963       28.549067   5171.981071  4.851937e+05   \n",
            "min      1.000000   21609.000000      -67.300000 -13038.000000  3.717000e+03   \n",
            "25%    125.750000   29003.000000       -5.900000    556.950000  3.658850e+04   \n",
            "50%    250.500000   40236.000000        0.550000   1761.600000  7.326150e+04   \n",
            "75%    375.250000   63926.750000        6.975000   3954.000000  1.805640e+05   \n",
            "max    500.000000  485873.000000      442.300000  45687.000000  3.473238e+06   \n",
            "\n",
            "       profit_change  previous_rank  years_on_global_500_list     employees  \\\n",
            "count     436.000000     500.000000                500.000000  5.000000e+02   \n",
            "mean       24.152752     222.134000                 15.036000  1.339983e+05   \n",
            "std       437.509566     146.941961                  7.932752  1.700878e+05   \n",
            "min      -793.700000       0.000000                  1.000000  3.280000e+02   \n",
            "25%       -22.775000      92.750000                  7.000000  4.293250e+04   \n",
            "50%        -0.350000     219.500000                 17.000000  9.291050e+04   \n",
            "75%        17.700000     347.250000                 23.000000  1.689172e+05   \n",
            "max      8909.500000     500.000000                 23.000000  2.300000e+06   \n",
            "\n",
            "       total_stockholder_equity  \n",
            "count                500.000000  \n",
            "mean               30628.076000  \n",
            "std                43642.576833  \n",
            "min               -59909.000000  \n",
            "25%                 7553.750000  \n",
            "50%                15809.500000  \n",
            "75%                37828.500000  \n",
            "max               301893.000000  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qozEt3qdv4Zc"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.3 Selecting Columns From a DataFrame by Label\n"
      ]
    },
    {
      "metadata": {
        "id": "yGBWO8oM2oFL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "By looking at the results produced by the **DataFrame.head()** and **DataFrame.tail()** methods in the previous screen, we can see that our data set seems to be pre-sorted in order of Fortune 500 rank.\n",
        "\n",
        "We can also see that the **DataFrame.info()** method showed us the number of entries in our index (representing the number of rows), a list of each column with their dtype and the number of non-null values, as well as a summary of the different dtypes and memory usage. In pandas, null values are represented using NaN.\n",
        "\n",
        "Because our axes in pandas have labels, we can select data using those labels. To do this, we use the [DataFrame.loc[]](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html#pandas.DataFrame.loc) method.\n",
        "\n",
        "Throughout our pandas lessons you'll see **df** used in code examples as shorthand for a dataframe object. We use this convention because you also see this throughout the official pandas documentation, so getting used to reading it is important. You'll notice that we use brackets **([])** instead of parentheses **(())** when selecting by location.  The syntax for the **DataFrame.loc[]** method is:\n",
        "\n",
        "```python\n",
        "df.loc[row, column]\n",
        "```\n",
        "\n",
        "Where **row** and **column** refer to row and column labels respectively, and can be one of:\n",
        "\n",
        "- A single label.\n",
        "- A list or array of labels.\n",
        "- A slice object with labels.\n",
        "- A boolean array.\n",
        "\n",
        "We'll look at boolean arrays later in this mission - for now, we're going to focus on the first three options. We're going to use the same selection of data we used in the previous screen, which is stored using the variable name **f500_selection** to make these examples easier.\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1WNexstd5iVGtj04VxjcnQSqa-UTSETDg\">\n",
        "\n",
        "\n",
        "In each of these examples, we're going to use **:** to specify that we wish to select all rows, so we can focus making selections using column labels only.\n",
        "\n",
        "First, let's select a single column by specifying a single label:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=15V82UWlysJjrA_Eg0b5vKPeMcagBhQCI\">\n",
        "\n",
        "\n",
        "Selecting a single column returns a pandas series. We'll talk about pandas series objects more in the next screen, but for now the important thing is to note that the new series has the same index axis labels as the original dataframe. Let's look at how we can use a list of labels to select specific columns:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1MSj7K1OU_0LwnKACxpYLOTfU71faWb4h\">\n",
        "\n",
        "\n",
        "When we use a list of labels, a dataframe is returned with only the columns specified in our list, in the order specified in our list. Just like when we used a single column label, the new dataframe has the same index axis labels as the original. Lets finish by using a **slice object with labels** to select specific columns.\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1CEtF_oFReD_-6pqheEfEd4nRWgakEgXQ\">\n",
        "\n",
        "Again we get a dataframe object, with all of the columns from the first up until **and including** the last column in our slice. \n",
        "\n",
        "Let's practice using these techniques to select specific columns from our f500 dataframe.\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "1. Select the **industry** column, and assign the result to the variable name **industries**.\n",
        "2. Select the **rank**, **previous_rank** and **years_on_global_500_list** columns, in order, and assign the result to the variable name **previous**.\n",
        "3. Select all columns from **revenues** up to and including **profit_change**, in order, and assign the result to the variable name **financial_data**."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TU2gt3piwuXx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5913
        },
        "outputId": "7206a98d-2ede-4557-aedf-c37620531cef"
      },
      "cell_type": "code",
      "source": [
        "# put your code\n",
        "industries = f500.loc[:,\"industry\"]\n",
        "previous = f500.loc[:, [\"rank\", \"previous\", \"years_on_global_500_list\"]]\n",
        "financial_data = f500.loc[:,\"revenues\":\"profit_change\"]\n",
        "\n",
        "print(industries[5:])\n",
        "print(previous[5:])\n",
        "print(financial_data[5:])\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Volkswagen                                                            Motor Vehicles and Parts\n",
            "Royal Dutch Shell                                                           Petroleum Refining\n",
            "Berkshire Hathaway                                    Insurance: Property and Casualty (Stock)\n",
            "Apple                                                              Computers, Office Equipment\n",
            "Exxon Mobil                                                                 Petroleum Refining\n",
            "McKesson                                                              Wholesalers: Health Care\n",
            "BP                                                                          Petroleum Refining\n",
            "UnitedHealth Group                                     Health Care: Insurance and Managed Care\n",
            "CVS Health                                            Health Care: Pharmacy and Other Services\n",
            "Samsung Electronics                                             Electronics, Electrical Equip.\n",
            "Glencore                                                          Mining, Crude-Oil Production\n",
            "Daimler                                                               Motor Vehicles and Parts\n",
            "General Motors                                                        Motor Vehicles and Parts\n",
            "AT&T                                                                        Telecommunications\n",
            "EXOR Group                                                              Diversified Financials\n",
            "Ford Motor                                                            Motor Vehicles and Parts\n",
            "Industrial & Commercial Bank of China                            Banks: Commercial and Savings\n",
            "AmerisourceBergen                                                     Wholesalers: Health Care\n",
            "China State Construction Engineering                                 Engineering, Construction\n",
            "AXA                                                            Insurance: Life, Health (stock)\n",
            "Amazon.com                                                     Internet Services and Retailing\n",
            "Hon Hai Precision Industry                                      Electronics, Electrical Equip.\n",
            "China Construction Bank                                          Banks: Commercial and Savings\n",
            "Honda Motor                                                           Motor Vehicles and Parts\n",
            "Total                                                                       Petroleum Refining\n",
            "General Electric                                                          Industrial Machinery\n",
            "Verizon                                                                     Telecommunications\n",
            "Japan Post Holdings                                            Insurance: Life, Health (stock)\n",
            "Allianz                                               Insurance: Property and Casualty (Stock)\n",
            "Cardinal Health                                                       Wholesalers: Health Care\n",
            "                                                                     ...                      \n",
            "Amgen                                                                          Pharmaceuticals\n",
            "Rabobank Group                                                   Banks: Commercial and Savings\n",
            "Altice                                                                      Telecommunications\n",
            "Onex                                            Semiconductors and Other Electronic Components\n",
            "US Foods Holding                                                 Wholesalers: Food and Grocery\n",
            "Shanxi Jincheng Anthracite Coal Mining Group                      Mining, Crude-Oil Production\n",
            "Randstad Holding                                                                Temporary Help\n",
            "Tencent Holdings                                               Internet Services and Retailing\n",
            "LG Display                                                      Electronics, Electrical Equip.\n",
            "Emirates Group                                                                        Airlines\n",
            "U.S. Bancorp                                                     Banks: Commercial and Savings\n",
            "H & M Hennes & Mauritz                                                     Specialty Retailers\n",
            "Aflac                                                          Insurance: Life, Health (stock)\n",
            "Sodexo                                                                           Food Services\n",
            "Suning Commerce Group                                                      Specialty Retailers\n",
            "GS Caltex                                                                   Petroleum Refining\n",
            "Ultrapar Holdings                                                                       Energy\n",
            "Xiamen C&D                                                                             Trading\n",
            "Sears Holdings                                                           General Merchandisers\n",
            "China General Technology                                             Engineering, Construction\n",
            "National Grid                                                                        Utilities\n",
            "Dollar General                                                             Specialty Retailers\n",
            "Telecom Italia                                                              Telecommunications\n",
            "Xiamen ITG Holding Group                                                               Trading\n",
            "Xinjiang Guanghui Industry Investment                                                  Trading\n",
            "Teva Pharmaceutical Industries                                                 Pharmaceuticals\n",
            "New China Life Insurance                                       Insurance: Life, Health (stock)\n",
            "Wm. Morrison Supermarkets                                                 Food and Drug Stores\n",
            "TUI                                                                            Travel Services\n",
            "AutoNation                                                                 Specialty Retailers\n",
            "Name: industry, Length: 495, dtype: object\n",
            "                                              rank  previous  \\\n",
            "Volkswagen                                       6       NaN   \n",
            "Royal Dutch Shell                                7       NaN   \n",
            "Berkshire Hathaway                               8       NaN   \n",
            "Apple                                            9       NaN   \n",
            "Exxon Mobil                                     10       NaN   \n",
            "McKesson                                        11       NaN   \n",
            "BP                                              12       NaN   \n",
            "UnitedHealth Group                              13       NaN   \n",
            "CVS Health                                      14       NaN   \n",
            "Samsung Electronics                             15       NaN   \n",
            "Glencore                                        16       NaN   \n",
            "Daimler                                         17       NaN   \n",
            "General Motors                                  18       NaN   \n",
            "AT&T                                            19       NaN   \n",
            "EXOR Group                                      20       NaN   \n",
            "Ford Motor                                      21       NaN   \n",
            "Industrial & Commercial Bank of China           22       NaN   \n",
            "AmerisourceBergen                               23       NaN   \n",
            "China State Construction Engineering            24       NaN   \n",
            "AXA                                             25       NaN   \n",
            "Amazon.com                                      26       NaN   \n",
            "Hon Hai Precision Industry                      27       NaN   \n",
            "China Construction Bank                         28       NaN   \n",
            "Honda Motor                                     29       NaN   \n",
            "Total                                           30       NaN   \n",
            "General Electric                                31       NaN   \n",
            "Verizon                                         32       NaN   \n",
            "Japan Post Holdings                             33       NaN   \n",
            "Allianz                                         34       NaN   \n",
            "Cardinal Health                                 35       NaN   \n",
            "...                                            ...       ...   \n",
            "Amgen                                          471       NaN   \n",
            "Rabobank Group                                 472       NaN   \n",
            "Altice                                         473       NaN   \n",
            "Onex                                           474       NaN   \n",
            "US Foods Holding                               475       NaN   \n",
            "Shanxi Jincheng Anthracite Coal Mining Group   476       NaN   \n",
            "Randstad Holding                               477       NaN   \n",
            "Tencent Holdings                               478       NaN   \n",
            "LG Display                                     479       NaN   \n",
            "Emirates Group                                 480       NaN   \n",
            "U.S. Bancorp                                   481       NaN   \n",
            "H & M Hennes & Mauritz                         482       NaN   \n",
            "Aflac                                          483       NaN   \n",
            "Sodexo                                         484       NaN   \n",
            "Suning Commerce Group                          485       NaN   \n",
            "GS Caltex                                      486       NaN   \n",
            "Ultrapar Holdings                              487       NaN   \n",
            "Xiamen C&D                                     488       NaN   \n",
            "Sears Holdings                                 489       NaN   \n",
            "China General Technology                       490       NaN   \n",
            "National Grid                                  491       NaN   \n",
            "Dollar General                                 492       NaN   \n",
            "Telecom Italia                                 493       NaN   \n",
            "Xiamen ITG Holding Group                       494       NaN   \n",
            "Xinjiang Guanghui Industry Investment          495       NaN   \n",
            "Teva Pharmaceutical Industries                 496       NaN   \n",
            "New China Life Insurance                       497       NaN   \n",
            "Wm. Morrison Supermarkets                      498       NaN   \n",
            "TUI                                            499       NaN   \n",
            "AutoNation                                     500       NaN   \n",
            "\n",
            "                                              years_on_global_500_list  \n",
            "Volkswagen                                                          23  \n",
            "Royal Dutch Shell                                                   23  \n",
            "Berkshire Hathaway                                                  21  \n",
            "Apple                                                               15  \n",
            "Exxon Mobil                                                         23  \n",
            "McKesson                                                            23  \n",
            "BP                                                                  23  \n",
            "UnitedHealth Group                                                  21  \n",
            "CVS Health                                                          22  \n",
            "Samsung Electronics                                                 23  \n",
            "Glencore                                                             7  \n",
            "Daimler                                                             23  \n",
            "General Motors                                                      23  \n",
            "AT&T                                                                23  \n",
            "EXOR Group                                                           7  \n",
            "Ford Motor                                                          23  \n",
            "Industrial & Commercial Bank of China                               19  \n",
            "AmerisourceBergen                                                   18  \n",
            "China State Construction Engineering                                 6  \n",
            "AXA                                                                 23  \n",
            "Amazon.com                                                           9  \n",
            "Hon Hai Precision Industry                                          13  \n",
            "China Construction Bank                                             18  \n",
            "Honda Motor                                                         23  \n",
            "Total                                                               23  \n",
            "General Electric                                                    23  \n",
            "Verizon                                                             23  \n",
            "Japan Post Holdings                                                 21  \n",
            "Allianz                                                             23  \n",
            "Cardinal Health                                                     20  \n",
            "...                                                                ...  \n",
            "Amgen                                                                2  \n",
            "Rabobank Group                                                      23  \n",
            "Altice                                                               1  \n",
            "Onex                                                                18  \n",
            "US Foods Holding                                                     2  \n",
            "Shanxi Jincheng Anthracite Coal Mining Group                         5  \n",
            "Randstad Holding                                                     5  \n",
            "Tencent Holdings                                                     1  \n",
            "LG Display                                                           6  \n",
            "Emirates Group                                                       2  \n",
            "U.S. Bancorp                                                        12  \n",
            "H & M Hennes & Mauritz                                               2  \n",
            "Aflac                                                               10  \n",
            "Sodexo                                                              18  \n",
            "Suning Commerce Group                                                1  \n",
            "GS Caltex                                                            6  \n",
            "Ultrapar Holdings                                                    8  \n",
            "Xiamen C&D                                                           1  \n",
            "Sears Holdings                                                      23  \n",
            "China General Technology                                             4  \n",
            "National Grid                                                       12  \n",
            "Dollar General                                                       1  \n",
            "Telecom Italia                                                      18  \n",
            "Xiamen ITG Holding Group                                             1  \n",
            "Xinjiang Guanghui Industry Investment                                1  \n",
            "Teva Pharmaceutical Industries                                       1  \n",
            "New China Life Insurance                                             2  \n",
            "Wm. Morrison Supermarkets                                           13  \n",
            "TUI                                                                 23  \n",
            "AutoNation                                                          12  \n",
            "\n",
            "[495 rows x 3 columns]\n",
            "                                              revenues  revenue_change  \\\n",
            "Volkswagen                                      240264             1.5   \n",
            "Royal Dutch Shell                               240033           -11.8   \n",
            "Berkshire Hathaway                              223604             6.1   \n",
            "Apple                                           215639            -7.7   \n",
            "Exxon Mobil                                     205004           -16.7   \n",
            "McKesson                                        198533             3.1   \n",
            "BP                                              186606           -17.4   \n",
            "UnitedHealth Group                              184840            17.7   \n",
            "CVS Health                                      177526            15.8   \n",
            "Samsung Electronics                             173957            -2.0   \n",
            "Glencore                                        173883             2.0   \n",
            "Daimler                                         169483             2.2   \n",
            "General Motors                                  166380             9.2   \n",
            "AT&T                                            163786            11.6   \n",
            "EXOR Group                                      154894             1.5   \n",
            "Ford Motor                                      151800             1.5   \n",
            "Industrial & Commercial Bank of China           147675           -11.7   \n",
            "AmerisourceBergen                               146850             8.0   \n",
            "China State Construction Engineering            144505             3.1   \n",
            "AXA                                             143722            11.2   \n",
            "Amazon.com                                      135987            27.1   \n",
            "Hon Hai Precision Industry                      135129            -4.3   \n",
            "China Construction Bank                         135093            -8.7   \n",
            "Honda Motor                                     129198             6.2   \n",
            "Total                                           127925           -10.8   \n",
            "General Electric                                126661            -9.8   \n",
            "Verizon                                         125980            -4.3   \n",
            "Japan Post Holdings                             122990             3.6   \n",
            "Allianz                                         122196            -0.6   \n",
            "Cardinal Health                                 121546            18.5   \n",
            "...                                                ...             ...   \n",
            "Amgen                                            22991             6.1   \n",
            "Rabobank Group                                   22956            -4.4   \n",
            "Altice                                           22953            42.2   \n",
            "Onex                                             22943             3.8   \n",
            "US Foods Holding                                 22919            -0.9   \n",
            "Shanxi Jincheng Anthracite Coal Mining Group     22875           -17.0   \n",
            "Randstad Holding                                 22873             7.3   \n",
            "Tencent Holdings                                 22871            39.7   \n",
            "LG Display                                       22840            -9.0   \n",
            "Emirates Group                                   22799             0.3   \n",
            "U.S. Bancorp                                     22744             5.8   \n",
            "H & M Hennes & Mauritz                           22618             4.6   \n",
            "Aflac                                            22559             8.1   \n",
            "Sodexo                                           22477            -2.0   \n",
            "Suning Commerce Group                            22366             3.7   \n",
            "GS Caltex                                        22207           -11.4   \n",
            "Ultrapar Holdings                                22167            -2.3   \n",
            "Xiamen C&D                                       22145             6.6   \n",
            "Sears Holdings                                   22138           -12.0   \n",
            "China General Technology                         22113           -20.1   \n",
            "National Grid                                    22036            -3.2   \n",
            "Dollar General                                   21987             7.9   \n",
            "Telecom Italia                                   21941           -17.4   \n",
            "Xiamen ITG Holding Group                         21930            34.3   \n",
            "Xinjiang Guanghui Industry Investment            21919            31.1   \n",
            "Teva Pharmaceutical Industries                   21903            11.5   \n",
            "New China Life Insurance                         21796           -13.3   \n",
            "Wm. Morrison Supermarkets                        21741           -11.3   \n",
            "TUI                                              21655            -5.5   \n",
            "AutoNation                                       21609             3.6   \n",
            "\n",
            "                                              profits   assets  profit_change  \n",
            "Volkswagen                                     5937.3   432116            NaN  \n",
            "Royal Dutch Shell                              4575.0   411275          135.9  \n",
            "Berkshire Hathaway                            24074.0   620854            NaN  \n",
            "Apple                                         45687.0   321686          -14.4  \n",
            "Exxon Mobil                                    7840.0   330314          -51.5  \n",
            "McKesson                                       5070.0    60969          124.5  \n",
            "BP                                              115.0   263316            NaN  \n",
            "UnitedHealth Group                             7017.0   122810           20.7  \n",
            "CVS Health                                     5317.0    94462            1.5  \n",
            "Samsung Electronics                           19316.5   217104           16.8  \n",
            "Glencore                                       1379.0   124600            NaN  \n",
            "Daimler                                        9428.4   256262            0.9  \n",
            "General Motors                                 9427.0   221690           -2.7  \n",
            "AT&T                                          12976.0   403821           -2.8  \n",
            "EXOR Group                                      651.3   186172          -21.1  \n",
            "Ford Motor                                     4596.0   237951          -37.7  \n",
            "Industrial & Commercial Bank of China         41883.9  3473238           -5.0  \n",
            "AmerisourceBergen                              1427.9    33656            NaN  \n",
            "China State Construction Engineering           2492.9   201269           10.7  \n",
            "AXA                                            6446.0   941556            3.5  \n",
            "Amazon.com                                     2371.0    83402          297.8  \n",
            "Hon Hai Precision Industry                     4608.8    80436           -0.4  \n",
            "China Construction Bank                       34840.9  3016578           -4.0  \n",
            "Honda Motor                                    5690.3   170165           98.3  \n",
            "Total                                          6196.0   230978           21.8  \n",
            "General Electric                               8831.0   365183            NaN  \n",
            "Verizon                                       13127.0   244180          -26.6  \n",
            "Japan Post Holdings                            -267.4  2631385         -107.5  \n",
            "Allianz                                        7611.5   932091            3.7  \n",
            "Cardinal Health                                1427.0    34122           17.4  \n",
            "...                                               ...      ...            ...  \n",
            "Amgen                                          7722.0    77626           11.3  \n",
            "Rabobank Group                                  828.3   698790          -15.1  \n",
            "Altice                                        -1722.5    84805            NaN  \n",
            "Onex                                           -130.0    42913            NaN  \n",
            "US Foods Holding                                209.8     8945           25.2  \n",
            "Shanxi Jincheng Anthracite Coal Mining Group      3.0    32954            NaN  \n",
            "Randstad Holding                                650.2     9624           13.0  \n",
            "Tencent Holdings                               6185.9    56968           35.0  \n",
            "LG Display                                      781.4    20606           -8.6  \n",
            "Emirates Group                                  340.3    33096          -82.5  \n",
            "U.S. Bancorp                                   5888.0   445964            0.2  \n",
            "H & M Hennes & Mauritz                         2192.3    10681          -12.3  \n",
            "Aflac                                          2659.0   129819            5.0  \n",
            "Sodexo                                          707.2    15766          -12.7  \n",
            "Suning Commerce Group                           106.0    19738          -23.6  \n",
            "GS Caltex                                      1221.1    15969           42.1  \n",
            "Ultrapar Holdings                               447.5     7426           -0.8  \n",
            "Xiamen C&D                                      280.2    21729           15.6  \n",
            "Sears Holdings                                -2221.0     9362            NaN  \n",
            "China General Technology                        413.6    20860          -20.8  \n",
            "National Grid                                 10150.6    82310          160.2  \n",
            "Dollar General                                 1251.1    11672            7.4  \n",
            "Telecom Italia                                 1999.4    74295            NaN  \n",
            "Xiamen ITG Holding Group                         35.6    12161          -25.1  \n",
            "Xinjiang Guanghui Industry Investment           251.8    31957           49.9  \n",
            "Teva Pharmaceutical Industries                  329.0    92890          -79.3  \n",
            "New China Life Insurance                        743.9   100609          -45.6  \n",
            "Wm. Morrison Supermarkets                       406.4    11630           20.4  \n",
            "TUI                                            1151.7    16247          195.5  \n",
            "AutoNation                                      430.5    10060           -2.7  \n",
            "\n",
            "[495 rows x 5 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: \n",
            "Passing list-likes to .loc or [] with any missing label will raise\n",
            "KeyError in the future, you can use .reindex() as an alternative.\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1367: FutureWarning: \n",
            "Passing list-likes to .loc or [] with any missing label will raise\n",
            "KeyError in the future, you can use .reindex() as an alternative.\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
            "  return self._getitem_tuple(key)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "H64LApNI2vKJ"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.4 Column selection shortcuts\n"
      ]
    },
    {
      "metadata": {
        "id": "TWYgWMke6m3R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "There are two shortcuts that pandas provides for accessing columns.\n",
        "\n",
        "1. **Single Bracket**  Instead of **df.loc[:,\"col_1\"]** you can use **df[\"col1\"]** to select columns. This works for single columns and lists of columns but not for for column slices. \n",
        "2. **Dot Accessor**  Instead of **df.loc[:,\"col_1\"]** you can use **df.col_1**. This shortcut does not work for labels that contain spaces or special characters. \n",
        "\n",
        "These shortcuts are designed to make some of the more common selection tasks easier. We recommend you always use the common shorthand in your code, as it will make your code easier to read. A summary of the techniques we've learned so far is below:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1BlhNf3XAGs0E50GISg0-W0sZXcRowrRe\">\n",
        "\n",
        "Let's practice selecting data by column some more, this time using the common shorthand method.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "1. Select the **country** column, and assign the result to the variable name **countries**.\n",
        "2. Select the **revenues** and **years_on_global_500_list** columns, in order, and assign the result to the variable name **revenues_years**.\n",
        "3. Select all columns from **ceo** up to and including **sector**, in order, and assign the result to the variable name **ceo_to_sector**.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aR-77Tqb49NM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "6a292d66-e4b1-4e6d-c575-46688d503055"
      },
      "cell_type": "code",
      "source": [
        "# put your code here\n",
        "countries = f500.country\n",
        "revenues_years = f500[[\"revenues\", \"years_on_global_500_list\"]]\n",
        "ceo_to_sector = f500.loc[:,\"ceo\":\"sector\"]\n",
        "\n",
        "print(countries.head(2))\n",
        "print(revenues_years.head(2))\n",
        "print(ceo_to_sector.head(2))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Walmart         USA\n",
            "State Grid    China\n",
            "Name: country, dtype: object\n",
            "            revenues  years_on_global_500_list\n",
            "Walmart       485873                        23\n",
            "State Grid    315199                        17\n",
            "                            ceo               industry     sector\n",
            "Walmart     C. Douglas McMillon  General Merchandisers  Retailing\n",
            "State Grid              Kou Wei              Utilities     Energy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5NajzEqj6Usm"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.5 Selecting Items from a Series by Label\n"
      ]
    },
    {
      "metadata": {
        "id": "aLLK0RFU7JlT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "In the last section we observed that when you select just one column of a dataframe, you get a new pandas type: a **series object**. Series is the pandas type for one-dimensional objects. Anytime you see a 1D pandas object, it will be a series, and anytime you see a 2D pandas object, it will be a dataframe.\n",
        "\n",
        "You might like to think of a dataframe as being a collection of series objects, which is similar to how pandas stores the data behind the scenes.\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1xNxF1TgmYOzlYj6ogofxKBiSO7FqsHOH\">\n",
        "\n",
        "\n",
        "To better understand the relationship between dataframe and series objects, we'll look at some examples. We'll start by looking at two pandas operations that each produce a series object:\n",
        "\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1aI-saLdbP4eZOQKGjHTJT54mFCa2Vu42\">\n",
        "\n",
        "Because a series has only one axis, its axis labels are either the index axis or column axis labels, depending on whether it is representing a row or a column from the original dataframe. If we make a 2D selection from a dataframe, it will retain the labels from both axes:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1YyiMWxDLQ8bo4vkL1qZc5Pq49C4KNqE8\">\n",
        "\n",
        "Let's look at a brief summary of the differences between dataframes and series'.\n",
        "\n",
        "\n",
        "<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1k7GgAAgsHY8YD-Z8x7Enerozt9MlqkuR\">\n",
        "\n",
        "\n",
        "Just like dataframes, we can use **Series.loc[]** to select items from a series using single labels, a list, or a slice object. We can also omit **loc[]** and use bracket shortcuts for all three. Let's look at an example:\n",
        "\n",
        "```python\n",
        ">>> print(s)\n",
        "\n",
        "a    0\n",
        "b    1\n",
        "c    2\n",
        "d    3\n",
        "e    4\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "We can select a single item:\n",
        "\n",
        "```python\n",
        "print(s[\"d\"])\n",
        "\n",
        "3\n",
        "```\n",
        "\n",
        "Like with dataframe columns, there is a dot accessor (eg, **s.d**) available, but this rarely used even less than the dataframe dot accessor.\n",
        "\n",
        "To select several items using a list:\n",
        "\n",
        "```python\n",
        "print(s[[\"a\", \"e\", \"c\"]])\n",
        "\n",
        "a    0\n",
        "e    4\n",
        "c    2\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "And lastly, several items using a slice:\n",
        "\n",
        "```python\n",
        "print(s[\"a\":\"d\"])\n",
        "\n",
        "a    0\n",
        "b    1\n",
        "c    2\n",
        "d    3\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "Let's practice selecting data from pandas series':\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "1. From the pandas series **ceos**:\n",
        "  -  Select the item at index label **Walmart** and assign the result to the variable name **walmart**.\n",
        "  -  Select the items from index label **Apple** up to and including index label **Samsung Electronics** and assign the result to the variable name **apple_to_samsung**.\n",
        "  -  Select the items with index labels **Exxon Mobil**, **BP**, and **Chevron**, in order, and assign the result to the variable name **oil_companies**.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "u9MZtd2x7KJk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ceos = f500[\"ceo\"]\n",
        "\n",
        "# put your code here\n",
        "walmart = f500[\"Walmart\"]\n",
        "apple_to_samsung = f500[\"Apple\":\"Samsung\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OtV3NQPnAgM5"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.6 Selecting Rows From a DataFrame by Label\n"
      ]
    },
    {
      "metadata": {
        "id": "h4q4Y1I37Plt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now that we've learned how to select columns using the labels of the **'column'** axis, let's learn how to select rows using the labels of the **'index'** axis.\n",
        "\n",
        "<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1HH7k0yK6abEG4xKiHgPTt5I_rz1OE5UD\">\n",
        "\n",
        "Selecting **rows** from a dataframe by label uses the same syntax as we use for **columns.** As a reminder:\n",
        "\n",
        "```python\n",
        "df.loc[row, column]\n",
        "```\n",
        "\n",
        "Where **row** and **column** refer to row and column labels. We'll look at how to select rows, again using our **f500_selection** dataframe to make these examples easier.\n",
        "\n",
        "```python\n",
        "print(type(f500_selection)\n",
        "print(f500_selection)\n",
        "```\n",
        "\n",
        "```python\n",
        "class 'pandas.core.frame.DataFrame'\n",
        "\n",
        "                          rank  revenues  profits country\n",
        "Walmart                      1    485873  13643.0     USA\n",
        "State Grid                   2    315199   9571.3   China\n",
        "Sinopec Group                3    267518   1257.9   China\n",
        "China National Petroleum     4    262573   1867.5   China\n",
        "Toyota Motor                 5    254694  16899.3   Japan\n",
        "```\n",
        "\n",
        "To select a single row:\n",
        "\n",
        "```python\n",
        "single_row = f500_selection.loc[\"Sinopec Group\"]\n",
        "print(type(single_row))\n",
        "print(single_row)\n",
        "\n",
        "class 'pandas.core.series.Series'\n",
        "\n",
        "rank             3\n",
        "revenues    267518\n",
        "profits     1257.9\n",
        "country      China\n",
        "Name: Sinopec Group, dtype: object\n",
        "```\n",
        "\n",
        "As we would expect, a single row is returned as a series. We should take a moment to note that the dtype of this series is object. Because this series has to store integer, float, and string values pandas uses the object dtype, since none of the numeric types could cater for all values.\n",
        "\n",
        "To select a list of rows:\n",
        "\n",
        "```python\n",
        "list_rows = f500_selection.loc[[\"Toyota Motor\", \"Walmart\"]]\n",
        "print(type(list_rows))\n",
        "print(list_rows)\n",
        "\n",
        "class 'pandas.core.frame.DataFrame'\n",
        "\n",
        "              rank  revenues  profits country\n",
        "Toyota Motor     5    254694  16899.3   Japan\n",
        "Walmart          1    485873  13643.0     USA\n",
        "```\n",
        "\n",
        "For selection using slices, we can use the shortcut without brackets. This is the reason we can't use this shortcut for columns - because it's reserved for use with rows:\n",
        "\n",
        "```python\n",
        "slice_rows = f500_selection[\"State Grid\":\"Toyota Motor\"]\n",
        "print(type(slice_rows))\n",
        "print(slice_rows)\n",
        "```\n",
        "\n",
        "```python\n",
        "class 'pandas.core.frame.DataFrame'\n",
        "\n",
        "                          rank  revenues  profits country\n",
        "State Grid                   2    315199   9571.3   China\n",
        "Sinopec Group                3    267518   1257.9   China\n",
        "China National Petroleum     4    262573   1867.5   China\n",
        "Toyota Motor                 5    254694  16899.3   Japan\n",
        "```\n",
        "\n",
        "Let's take a look at a summary of all the different label selection methods we've learned so far:\n",
        "\n",
        "\n",
        "<img width=\"800\" src=\"https://drive.google.com/uc?export=view&id=1rQMPkOZBVh57x6kVu5qWjU3UC6vCh9v_\">\n",
        "\n",
        "\n",
        "Now for some practice - we're going to make it a little bit harder this time, by asking you to combine selection methods for rows and columns on both dataframes and series!\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "1. By selecting data from **f500**:\n",
        "  - Create a new variable, **drink_companies**, with:\n",
        "    - Rows with indicies **Anheuser-Busch InBev**, **Coca-Cola**, and **Heineken Holding**, in that order.\n",
        "     - All columns.\n",
        "  - Create a new variable **big_movers**, with:\n",
        "    - Rows with indicies **Aviva**, **HP**, **JD.com**, and **BHP Billiton**, in that order.\n",
        "    - The **rank** and **previous_rank** columns, in that order.\n",
        "  - Create a new variable, **middle_companies** with:\n",
        "    - All rows with indicies from **Tata Motors** to **Nationwide**, inclusive.\n",
        "    - All columns from **rank** to **country**, inclusive."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yrqIppYaB60O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6hN_9QIlH7ey"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.7 Series and Dataframe Describe Methods\n"
      ]
    },
    {
      "metadata": {
        "id": "eaBTv4_57ng8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "We're starting to get a feel for how axes labels in pandas make selecting data much easier. Pandas also has a large number of methods and functions that make working with data easier. Let's use a few of these to explore our Fortune 500 data.\n",
        "\n",
        "The first method we'll learn about is the [Series.describe()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.describe.html#pandas.Series.describe) method, which returns some descriptive statistics on the data contained within a specific pandas series. Let's look at an example:\n",
        "\n",
        "```python\n",
        "revs = f500[\"revenues\"]\n",
        "print(revs.describe())\n",
        "```\n",
        "\n",
        "```python\n",
        "count       500.000000\n",
        "mean      55416.358000\n",
        "std       45725.478963\n",
        "min       21609.000000\n",
        "25%       29003.000000\n",
        "50%       40236.000000\n",
        "75%       63926.750000\n",
        "max      485873.000000\n",
        "Name: revenues, dtype: float64\n",
        "```\n",
        "\n",
        "We've assigned the **revenues** column to a new series, **revs**, and then used the **describe()** method on that series. The method tells us how many non-null values are contained in the series, the mean and standard devation, along with the minimum, maximum and [quartile](https://en.wikipedia.org/wiki/Quartile) values.\n",
        "\n",
        "Rather than assigning the series to it's own variable, we can actually skip that step and use the method directly on the result of the column selection. This is called **method chaining** and is a way to combine multiple methods together in a single line. It's not unique to pandas, however it is something that you see a lot in pandas code. Let's see what the command looks like with method chaining, using the **assets** column.\n",
        "\n",
        "\n",
        "```python\n",
        "print(f500[\"assets\"].describe())\n",
        "```\n",
        "\n",
        "```python\n",
        "count    5.000000e+02\n",
        "mean     2.436323e+05\n",
        "std      4.851937e+05\n",
        "min      3.717000e+03\n",
        "25%      3.658850e+04\n",
        "50%      7.326150e+04\n",
        "75%      1.805640e+05\n",
        "max      3.473238e+06\n",
        "Name: assets, dtype: float64\n",
        "```\n",
        "\n",
        "From here, you'll start to see method chaining used more in our missions. When writing code, you should always assess whether method chaining will make your code harder to read. It's always preferable to break out into more than one line if it will make your code easier to understand.\n",
        "\n",
        "You might have noticed that the values in the code segment above look a little bit different. Because the values for this column are too long to display neatly, pandas has displayed them in **E-notation**, a type of [scientific notation](https://en.wikipedia.org/wiki/Scientific_notation). Here is an expansion of what the E-notation represents:\n",
        "\n",
        "| Original Notation | Expanded Formula | Result |\n",
        "|-------------------|--------------------|----------|\n",
        "| 5.000000E+02 | 5.000000 * 10 ** 2 | 500 |\n",
        "| 2.436323E+05 | 2.436323 * 10 ** 5 | 243632.3 |\n",
        "\n",
        "\n",
        "If we use **describe()** on a column that contains non-numeric values, we get some different statistics. Let's look at an example:\n",
        "\n",
        "```python\n",
        "print(f500[\"country\"].describe())\n",
        "\n",
        "count     500\n",
        "unique     34\n",
        "top       USA\n",
        "freq      132\n",
        "Name: country, dtype: object\n",
        "```\n",
        "\n",
        "Here is what the output indicates:\n",
        "\n",
        "The first statistic, **count**, is the same as for numeric columns, showing us the number of non-null values. The other three statistics are new:\n",
        "\n",
        "- **unique** - The number of unique values in the series. In this case, it tells us that there are 34 different countries represented in the Fortune 500.\n",
        "- **top** - The most common value in the series. The USA is the most common country that a company in the Fortune 500 is headquartered in.\n",
        "- **freq** - The frequency of the most common value. The USA is the country that 132 companies from Fortune 500 are headquartered in.\n",
        "\n",
        "Because series' and dataframes are two distinct objects, they have their own unique methods. There are many times where both series and dataframe objects have a method of the same name that behaves in similar ways. DataFrame objects also have a [DataFrame.describe()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method that returns these same statistics for every column. If you like, you can take a look at the documentation using the link in the previous sentence to familiarize yourself with some of the differences between the two methods.\n",
        "\n",
        "One difference is that you need to specify manually if you want to see the statistics for the non-numeric columns. By default, **DataFrame.describe()** will return statistics for only numeric columns. If we wanted to get just the object columns, we need to use the **include=['O']** parameter when using the dataframe version of describe:\n",
        "\n",
        "```python\n",
        "print(f500.describe(include=['O']))\n",
        "```\n",
        "\n",
        "```python\n",
        "_            ceo    industry     sector  country  hq_location    website\n",
        "count        500         500        500      500          500        500\n",
        "unique       500          58         21       34          235        500\n",
        "top     Xavie...   Banks:...  Financ...      USA  Beijing,...  http:/...\n",
        "freq           1          51        118      132           56          1\n",
        "```\n",
        "\n",
        "Another difference is that **Series.describe()** returns a series object, where **DataFrame.describe()** returns a dataframe object. \n",
        "\n",
        "Let's practice using both the series and dataframe describe methods:\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "1. Use the appropriate **describe()** method to:\n",
        "  - Return a series of descriptive statistics for the **profits** column, and assign the result to **profits_desc**.\n",
        "  - Return a dataframe of descriptive statistics for the **revenues** and **employees** columns, in order, and assign the result to **revenue_and_employees_desc**.\n",
        "  - Return a dataframe of descriptive statistics for every column in the **f500** dataframe, by checking the documentation for the correct value for the **include** parameter, and assign the result to **all_desc**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "h43tBXdoKpnl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "F8871OlQNvYW"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.8 More Data Exploration Methods\n"
      ]
    },
    {
      "metadata": {
        "id": "P5yeuEv877Bv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "One basic concept in Pandas are the vectorized operations. Let's look at an example of how this would work with a pandas series:\n",
        "\n",
        "```python\n",
        ">>> print(my_series)\n",
        "\n",
        "    0    1\n",
        "    1    2\n",
        "    2    3\n",
        "    3    4\n",
        "    4    5\n",
        "    dtype: int64\n",
        "\n",
        ">>> my_series = my_series + 10\n",
        "\n",
        ">>> print(my_series)\n",
        "\n",
        "    0    11\n",
        "    1    12\n",
        "    2    13\n",
        "    3    14\n",
        "    4    15\n",
        "    dtype: int64\n",
        "```\n",
        "\n",
        "Many of the descriptive stats methods are also supported. Here are a few handy methods (with links to documentation) that you might use when working with data in pandas:\n",
        "\n",
        "- [Series.max()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.max.html) and [DataFrame.max()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.max.html)\n",
        "- [Series.min()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.min.html) and [DataFrame.min()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.min.html)\n",
        "- [Series.mean()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.mean.html) and [DataFrame.mean()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mean.html)\n",
        "- [Series.median()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.median.html) and [DataFrame.median()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.median.html)\n",
        "- [Series.mode()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.mode.html) and [DataFrame.mode()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mode.html)\n",
        "- [Series.sum()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.sum.html) and [DataFrame.sum()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sum.html)\n",
        "\n",
        "\n",
        "As the documentation indicates, the series methods don't require an axis parameter, however the dataframe methods will so we know which axis to calculate across. While you can use integers to refer to the first and second axis, pandas dataframe methods also accept the strings **\"index\"** and **\"columns\"** for the axis parameter. Let's refresh our memory on how this works:\n",
        "\n",
        "<img width=\"700\" src=\"https://drive.google.com/uc?export=view&id=1euiSMOgXE7IVP_U-VIRzwV6JAXBpC4yx\">\n",
        "\n",
        "For instance, if we wanted to find the median (middle) value for the **revenues** and **profits** columns, we could use the following code:\n",
        "\n",
        "```python\n",
        "medians = f500[[\"revenues\", \"profits\"]].median(axis=0)\n",
        "# we could also use .median(axis=\"index\")\n",
        "print(medians)\n",
        "\n",
        "revenues    40236.0\n",
        "profits      1761.6\n",
        "dtype: float64\n",
        "  \n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "In fact, the default value for the axis parameter with these methods is **axis=0**, so we could have just used the **median()** method without a parameter to get the same result!\n",
        "\n",
        "Another extremely handy method for exploring data in pandas is the [Series.value_counts()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html) method. The **Series.value_counts()** method displays each unique non-null value from a series, with a count of the number of times that value is used. We saw above that the **sector** column has 21 unique values. Let's use **Series.value_counts()** to look at the top 5:\n",
        "\n",
        "```python\n",
        ">>> print(f500[\"sector\"].value_counts().head())\n",
        "\n",
        "    Financials                118\n",
        "    Energy                     80\n",
        "    Technology                 44\n",
        "    Motor Vehicles & Parts     34\n",
        "    Wholesalers                28\n",
        "    Name: sector, dtype: int64\n",
        "```\n",
        "\n",
        "Let's take a moment to walk through what happened in that line of code:\n",
        "\n",
        "- We used the **print()** function to print the output of the following method chain:\n",
        "    - Select the **sector** column from the **f500** dataframe, and on the resulting series\n",
        "    - Use the **Series.value_counts()** to produce a series of the unique values and their counts in order, and on the resulting series\n",
        "    - Use the [Series.head()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.head.html#pandas.Series.head) method to return the first 5 items only.\n",
        "    \n",
        "    \n",
        "We haven't seen the **Series.head()** method before, but it works similarly to **DataFrame.head()**, returning the first five items from a series, or a different number if you provide an argument.\n",
        "\n",
        "The **Series.value_counts()** method is one of the handiest methods to use when exploring a data set. It's also one of the few series methods that doesn't have a dataframe counterpart.\n",
        "\n",
        "Don't worry too much about having to remember which methods belong to which objects for now. You'll find that as you practice them some will stick, and for the rest you'll be able to reference the pandas documentation.\n",
        "\n",
        "Let's start the process by practicing some of these to explore the Fortune 500 some more!\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Use **Series.value_counts()** and **Series.head()** to return the 5 most common values for the **country** column, and assign the results to **top5_countries.**\n",
        "- Use **Series.value_counts()** and **Series.head()** to return the 5 most common values for the **previous rank** column, and assign the results to **top5_previous_rank**.\n",
        "- Use the appropriate **max()** method to find the maximum value for only the numeric columns from **f500** (you may need to check the documentation), and assign the result to the variable **max_f500**.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "H3PtJ5_lOIO5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SJNwnlxMS8fc"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.9 Assignment with pandas\n"
      ]
    },
    {
      "metadata": {
        "id": "ZbtBSYW58rM6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Looking at the results of the most common values for the **previous_rank** column in the last exercise, you might have noticed something a little odd:\n",
        "\n",
        "```python\n",
        ">>> print(top5_previous_rank.head())\n",
        "\n",
        "    0      33\n",
        "    159     1\n",
        "    147     1\n",
        "    148     1\n",
        "    149     1\n",
        "    Name: previous_rank, dtype: int64\n",
        "```\n",
        "\n",
        "This indicates that 33 companies had the value **0** for their rank in the Fortune 500 for the previous year. Given that a rank of zero doesn't exist, we might conclude that these companies didn't have a rank at all for the previous year. It would make more sense for us to replace these values with a null value to more clearly indicate that the value is missing. There are a few things we need to be able to do before we can correct this. The first is how to assign values using pandas.\n",
        "\n",
        "When we used NumPy, we learned that the same techniques that we use to select data could be used for assignment. Let's look at an example:\n",
        "\n",
        "\n",
        "```python\n",
        "my_array = np.array([1, 2, 3, 4])\n",
        "\n",
        "# to perform selection\n",
        "print(my_array[0])\n",
        "\n",
        "# to perform assignment\n",
        "my_array[0] = 99\n",
        "```\n",
        "\n",
        "The same is true with pandas. Let's look at this example:\n",
        "\n",
        "```python\n",
        ">>> top5_rank_revenue = f500[[\"rank\", \"revenues\"]].head()\n",
        "\n",
        ">>> print(top5_rank_revenue)\n",
        "                              rank  revenues\n",
        "    Walmart                      1    485873\n",
        "    State Grid                   2    315199\n",
        "    Sinopec Group                3    267518\n",
        "    China National Petroleum     4    262573\n",
        "    Toyota Motor                 5    254694\n",
        "\n",
        ">>> top5_rank_revenue[\"revenues\"] = 0\n",
        "\n",
        ">>> print(top5_rank_revenue)\n",
        "                              rank  revenues\n",
        "    Walmart                      1         0\n",
        "    State Grid                   2         0\n",
        "    Sinopec Group                3         0\n",
        "    China National Petroleum     4         0\n",
        "    Toyota Motor                 5         0\n",
        "    \n",
        "```\n",
        "\n",
        "\n",
        "When we selected a whole column by label and use assignment, we assigned the value to every item in that column.\n",
        "\n",
        "By providing labels for both axes, we can assign to a single value within our dataframe.\n",
        "\n",
        "```python\n",
        ">>> top5_rank_revenue.loc[\"Sinopec Group\", \"revenues\"] = 999\n",
        "\n",
        ">>> print(top5_rank_revenue)\n",
        "                              rank  revenues\n",
        "    Walmart                      1         0\n",
        "    State Grid                   2         0\n",
        "    Sinopec Group                3       999\n",
        "    China National Petroleum     4         0\n",
        "    Toyota Motor                 5         0\n",
        "```\n",
        "\n",
        "If we assign a value using a index or column label that does not exist, pandas will create a new row or column in our dataframe. Let's add a new column and new row to our **top5_rank_revenue** dataframe:\n",
        "\n",
        "```python\n",
        ">>> top5_rank_revenue[\"year_founded\"] = 0\n",
        "\n",
        ">>> print(top5_rank_revenue)\n",
        "\n",
        "                              rank  revenues  year_founded\n",
        "    Walmart                      1         0             0\n",
        "    State Grid                   2         0             0\n",
        "    Sinopec Group                3       999             0\n",
        "    China National Petroleum     4         0             0\n",
        "    Toyota Motor                 5         0             0\n",
        "\n",
        ">>> top5_rank_revenue.loc[\"My New Company\"] = 555\n",
        "\n",
        ">>> print(top5_rank_revenue)\n",
        "\n",
        "                              rank  revenues  year_founded\n",
        "    Walmart                      1         0             0\n",
        "    State Grid                   2         0             0\n",
        "    Sinopec Group                3       999             0\n",
        "    China National Petroleum     4         0             0\n",
        "    Toyota Motor                 5         0             0\n",
        "    My New Company             555       555           555\n",
        "```\n",
        "\n",
        "\n",
        "There is one exception to be aware of: You **can't** create a new row/column by attempting to use the dot accessor shortcut with a label that does not exist.\n",
        "\n",
        "Let's practice assigning values and adding new columns using our full Fortune 500 dataframe:\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Add a new column, **revenues_b** to the **f500** dataframe by using vectorized division to divide the values in the existing **revenues** column by 1000 (converting them from millions to billions).\n",
        "- The company **'Dow Chemical'** have named a new CEO. Update the value where the index label is **Dow Chemical** and for the **ceo** column to **Jim Fitterling**."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fbvJBQzLTuNX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "X0sKBpdxVMM_"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.10 Using Boolean Indexing with pandas Objects\n"
      ]
    },
    {
      "metadata": {
        "id": "TjV4t1KJ85GU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now that we know how assign values in pandas, we're one step closer to being able to correct the values in the **previous_rank** column that are **0**. If we knew the name of every single row label where this case was true, we could do this manually by using a list of labels when we performed our assignment.\n",
        "\n",
        "While it's helpful to be able to replace specific values in rows where we know the row label ahead of time, this is cumbersome when we want to do this for all rows that meet the same criteria. Another option would be to use a loop, but this would be slower and would lose the benefits of vectorization that pandas gives us. Instead, we can use **boolean indexing**.\n",
        "\n",
        "Just like NumPy, pandas allows us to use boolean indexing to select items based on their value, which will make our task a lot easier. Let's refresh our memory of how boolean indexing is used for selection, and learn how boolean indexing works in pandas.\n",
        "\n",
        "In NumPy, boolean arrays are created by performing a vectorized boolean comparison on a NumPy ndarray. In pandas this works almost identically, however the resulting boolean object will be either a series or a dataframe, depending on the object on which the boolean comparison was performed. Let's look an example of performing a boolean comparison on a series vs a dataframe:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1BJNbnwxzO7TBjbYhFJppw1o93Tnn7xMU\">\n",
        "\n",
        "\n",
        "It's much less common to use a boolean dataframe than a boolean series in pandas. You almost always want to use the results of a comparison on one column from dataframe (a series object) to select data in the main dataframe, or a selection of the main dataframe.\n",
        "\n",
        "Let's look at two examples of how that works in diagram form. For our example, we'll be working with this dataframe of people and their favorite numbers:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1FqhK-Kfr7u7JDeAbfEFxn3_0nONlIpp1\">\n",
        "\n",
        "Let's check which people have a favorite number of 8. We perform a vectorized boolean operation that produces a boolean series:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1OgQSNM8KwzI5Mr3UJ4Y-89tXdc9t6Ybg\">\n",
        "\n",
        "\n",
        "We can use that series to index the whole dataframe, leaving us the rows that correspond only to people whose favorite number is 8.\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1WeDutjUzaV2RqdHgJkSVWQNPOguqskak\">\n",
        "\n",
        "Note that we didn't used **loc[]**. This is because boolean arrays use the same shortcut as slices to select along the index axis. \n",
        "\n",
        "\n",
        "Now let's look at an example of using boolean indexing with our Fortune 500 dataset. We want find out which are the 5 most common countries for companies belonging to the **'Motor Vehicles and Parts'** industry.\n",
        "\n",
        "We start by making a boolean series that shows us which rows from our dataframe have the value of **Motor Vehicles and Parts** for the **industry** column. We'll then print the first five items of our boolean series so we can see it in action:\n",
        "\n",
        "\n",
        "```python\n",
        ">>> motor_bool = f500[\"industry\"] == \"Motor Vehicles and Parts\"\n",
        "\n",
        ">>> print(motor_bool.head())\n",
        "\n",
        "    Walmart                     False\n",
        "    State Grid                  False\n",
        "    Sinopec Group               False\n",
        "    China National Petroleum    False\n",
        "    Toyota Motor                 True\n",
        "    Name: industry, dtype: bool\n",
        "```\n",
        "\n",
        "\n",
        "Notice that like our examples in the diagrams above, the index labels are retained in our boolean series. Next, we use that boolean series to select only the rows that have **True** for our boolean index, and just the **country** column, and then print the first 5 items to check the values:\n",
        "\n",
        "```python\n",
        ">>> motor_countries = f500.loc[motor_bool, \"country\"]\n",
        "\n",
        ">>> print(motor_countries.head())\n",
        "\n",
        "    Toyota Motor        Japan\n",
        "    Volkswagen        Germany\n",
        "    Daimler           Germany\n",
        "    General Motors        USA\n",
        "    Ford Motor            USA\n",
        "    Name: country, dtype: object\n",
        "```\n",
        "\n",
        "\n",
        "Lastly, we can use the **value_counts()** method for the **motor_countries** series, chained to the **head()** method to produce a series of the top 5 countries for the 'Motor Vehicles and Parts' industry:\n",
        "\n",
        "```python\n",
        ">>> top5_motor_countries = motor_countries.value_counts().head()\n",
        "\n",
        ">>> print(top5_motor_countries)\n",
        "\n",
        "    Japan          10\n",
        "    China           7\n",
        "    Germany         6\n",
        "    France          3\n",
        "    South Korea     3\n",
        "    Name: country, dtype: int64\n",
        "```\n",
        "\n",
        "Let's practice using boolean indexing in pandas to identify the five highest ranked companies from South Korea. Remember, we observed earlier that the **f500** dataframe is already sorted by rank, so we won't need to perfom any extra sorting.\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Create a boolean series, **kr_bool**, that compares whether the values in the **country** column from the **f500** dataframe are equal to **\"South Korea\"**\n",
        "- Use that boolean series to index the full **f500** dataframe, assigning just the first five rows to **top_5_kr.**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bx5OBhlIVtDr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wF256cCCnWVa"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.11 Using Boolean Arrays to Assign Values\n"
      ]
    },
    {
      "metadata": {
        "id": "mii8Gwsi87VY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "We now have all the knowledge we need to fix the 0 values in the **previous_rank** column:\n",
        "\n",
        "- perform assignment in pandas\n",
        "- use boolean indexing in pandas\n",
        "\n",
        "Let's look at an example of how we combine these two operations together. For our example, we'll want to change the **'Motor Vehicles & Parts'** values in the **sector** column to **'Motor Vehicles and Parts'**  i.e. we will change the ampersand **(&)** to **and**.\n",
        "\n",
        "First, we create a boolean series by comparing the values in the sector column to **'Motor Vehicles & Parts'**.\n",
        "\n",
        "```python\n",
        "ampersand_bool = f500[\"sector\"] == \"Motor Vehicles & Parts\"\n",
        "```\n",
        "\n",
        "Next, we use that boolean series and the string **\"sector\"** to perform the assignment.\n",
        "\n",
        "```python\n",
        "f500.loc[ampersand_bool,\"sector\"] = \"Motor Vehicles and Parts\"\n",
        "```\n",
        "\n",
        "Just like we saw in the NumPy mission earlier in this course, we can remove the intermediate step of creating a boolean series, and combine everything into one line. This is the most common way to write pandas code to perform assignment using boolean arrays:\n",
        "\n",
        "```python\n",
        "f500.loc[f500[\"sector\"] == \"Motor Vehicles & Parts\",\"sector\"] = \"Motor Vehicles and Parts\"\n",
        "```\n",
        "\n",
        "Now we can follow this pattern to replace the values in the **previous_rank** column. We'll replace these values with **np.nan**, which is used in pandas, just as it is in numpy, to represent values that can't be represented numerically, most commonly missing values.\n",
        "\n",
        "To make comparing the values in this column before and after our operation easier, we've added the following line of code to the cell below:\n",
        "\n",
        "```python\n",
        "prev_rank_before = f500[\"previous_rank\"].value_counts(dropna=False).head()\n",
        "```\n",
        "\n",
        "This uses **Series.value_counts()** and **Series.head()** to display the 5 most common values in the **previous_rank** column, but adds an additional **dropna=False** parameter, which stops the **Series.value_counts()** method from excluding null values when it makes its calculation, as shown in the [Series.value_counts() documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html#pandas.Series.value_counts).\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Use boolean indexing to update values in the **previous_rank** column of the **f500** dataframe:\n",
        "  - Where previous there was a value of 0, there should now be a value of **np.nan**.\n",
        "  - It is up to you whether you assign the boolean series to its own variable first, or whether you complete the operation in one line.\n",
        "- Create a new pandas series, **prev_rank_after**, using the same syntax that was used to create the **prev_rank_before series.**\n",
        "- After you have run your code, use the variable inspector to compare **prev_rank_before** and **prev_rank_after.**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aAKjY4M6ozNI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "prev_rank_before = f500[\"previous_rank\"].value_counts(dropna=False).head()\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wjtwE9KKrF5Z"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.12 Challenge: Top Performers by Country\n"
      ]
    },
    {
      "metadata": {
        "id": "LJCxlf5O9NvB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "You may have noticed that after we assigned NaN values the previous_rank column changed dtype. Let's take a closer look:\n",
        "\n",
        "```python\n",
        ">>> print(prev_rank_before)\n",
        "\n",
        "    0      33\n",
        "    159     1\n",
        "    147     1\n",
        "    148     1\n",
        "    149     1\n",
        "\n",
        ">>> print(prev_rank_after)\n",
        "\n",
        "    NaN      33\n",
        "    471.0     1\n",
        "    234.0     1\n",
        "    125.0     1\n",
        "    166.0     1\n",
        "```\n",
        "\n",
        "The index of the series that **Series.value_counts()** produces is now showing us floats like 471.0 instead of the integers from before. The reason behind this is that pandas uses the NumPy integer dtype, which does not support NaN values. Pandas inherits this behavior, and in instances where you try and assign a NaN value to an integer column, pandas will silently convert that column to a float dtype. If you're interested in finding out more about this, [there is a specific section on integer NaN values in the pandas documentation](http://pandas.pydata.org/pandas-docs/stable/gotchas.html#nan-integer-na-values-and-na-type-promotions).\n",
        "\n",
        "We'll finish this mission with a challenge. In this challenge, we'll calculate a specific statistic or attribute of each of the three most common countries from our f500 dataframe. We've identified the three most common countries using the code below:\n",
        "\n",
        "```python\n",
        ">>> top_3_countries = f500[\"country\"].value_counts().head(3)\n",
        "\n",
        ">>> print(top_3_countries)\n",
        "\n",
        "USA      132\n",
        "China    109\n",
        "Japan     51\n",
        "Name: country, dtype: int64\n",
        "```\n",
        "\n",
        "Don't be discouraged if this takes a few attempts to get right working with data is an iterative process!\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "1. Create a series, **cities_usa**, containing counts of the five most common Headquarter Location cities for companies headquartered in the USA.\n",
        "2. Create a series, **sector_china**, containing counts of the three most common sectors for companies headquartered in the China.\n",
        "3. Create float object, **mean_employees_japan**, containing the mean average number of employees for companies headquartered in Japan"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3Z8ouPzEsktk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ITsazgBWsuJT"
      },
      "cell_type": "markdown",
      "source": [
        "In this lesson, we learned:\n",
        "\n",
        "- How pandas can be combined to make working with data easier\n",
        "- About the two core pandas types: series and dataframes\n",
        "- How to select data from pandas objects using axis labels\n",
        "- How to select data from pandas objects using boolean arrays\n",
        "- How to assign data using labels and boolean arrays\n",
        "- How to create new rows and columns in pandas\n",
        "- Many new methods to make data analysis easier in pandas."
      ]
    }
  ]
}